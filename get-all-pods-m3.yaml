apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      prometheus.io/path: /metrics
      prometheus.io/port: "9402"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-04-01T04:29:32Z"
    generateName: cert-manager-6dc66985d4-
    labels:
      app: cert-manager
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: cert-manager
      app.kubernetes.io/version: v1.14.4
      helm.sh/chart: cert-manager-v1.14.4
      pod-template-hash: 6dc66985d4
    name: cert-manager-6dc66985d4-8t6l8
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-6dc66985d4
      uid: fee7d62e-8d38-490c-a0b5-8fa8f5656674
    resourceVersion: "46089022"
    uid: 4e4f1aa9-a8d4-4c25-abda-3980fdba71ee
  spec:
    containers:
    - args:
      - --v=2
      - --cluster-resource-namespace=$(POD_NAMESPACE)
      - --leader-election-namespace=kube-system
      - --acme-http01-solver-image=quay.io/jetstack/cert-manager-acmesolver:v1.14.4
      - --max-concurrent-challenges=60
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-controller:v1.14.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          path: /livez
          port: http-healthz
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: cert-manager-controller
      ports:
      - containerPort: 9402
        name: http-metrics
        protocol: TCP
      - containerPort: 9403
        name: http-healthz
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-689d6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager
    serviceAccountName: cert-manager
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-689d6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6ff3f7117716e55827c182a8e23743a27703fcf9c0df6ff7921d9ef7ce506869
      image: quay.io/jetstack/cert-manager-controller:v1.14.4
      imageID: quay.io/jetstack/cert-manager-controller@sha256:5cffa969fd30ce6a760994d30e7cccb3626abc8015d813de52f8cfa9ff862de9
      lastState: {}
      name: cert-manager-controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:29:33Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.16
    podIPs:
    - ip: 192.168.0.16
    qosClass: BestEffort
    startTime: "2024-04-01T04:29:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T04:29:32Z"
    generateName: cert-manager-cainjector-c7d4dbdd9-
    labels:
      app: cainjector
      app.kubernetes.io/component: cainjector
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: cainjector
      app.kubernetes.io/version: v1.14.4
      helm.sh/chart: cert-manager-v1.14.4
      pod-template-hash: c7d4dbdd9
    name: cert-manager-cainjector-c7d4dbdd9-jlstt
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-cainjector-c7d4dbdd9
      uid: 4ad5f4b4-6ddc-4bad-8208-418435b3b8d7
    resourceVersion: "68535652"
    uid: b905aeb8-3633-4ca9-b350-df3a87cdd60e
  spec:
    containers:
    - args:
      - --v=2
      - --leader-election-namespace=kube-system
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-cainjector:v1.14.4
      imagePullPolicy: IfNotPresent
      name: cert-manager-cainjector
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-sktmn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager-cainjector
    serviceAccountName: cert-manager-cainjector
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-sktmn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1c7b0a11d4c38a0fce9c3abf2b69358eae486bf383344a18b730db6bf5e135a4
      image: quay.io/jetstack/cert-manager-cainjector:v1.14.4
      imageID: quay.io/jetstack/cert-manager-cainjector@sha256:30286297e5b4b71a86759d297a8109c6a1649fdc68d28f618d87edf12a2da417
      lastState: {}
      name: cert-manager-cainjector
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:29:33Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.14
    podIPs:
    - ip: 192.168.0.14
    qosClass: BestEffort
    startTime: "2024-04-01T04:29:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T04:29:32Z"
    generateName: cert-manager-webhook-847d7676c9-
    labels:
      app: webhook
      app.kubernetes.io/component: webhook
      app.kubernetes.io/instance: cert-manager
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: webhook
      app.kubernetes.io/version: v1.14.4
      helm.sh/chart: cert-manager-v1.14.4
      pod-template-hash: 847d7676c9
    name: cert-manager-webhook-847d7676c9-89rtq
    namespace: cert-manager
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: cert-manager-webhook-847d7676c9
      uid: 9ca18977-52e3-474e-93e7-cbcaba9a13fa
    resourceVersion: "68535663"
    uid: 4b127dff-feeb-4962-81b2-27b87d2a1418
  spec:
    containers:
    - args:
      - --v=2
      - --secure-port=10250
      - --dynamic-serving-ca-secret-namespace=$(POD_NAMESPACE)
      - --dynamic-serving-ca-secret-name=cert-manager-webhook-ca
      - --dynamic-serving-dns-names=cert-manager-webhook
      - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE)
      - --dynamic-serving-dns-names=cert-manager-webhook.$(POD_NAMESPACE).svc
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: quay.io/jetstack/cert-manager-webhook:v1.14.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 6080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: cert-manager-webhook
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      - containerPort: 6080
        name: healthcheck
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 6080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9657m
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: cert-manager-webhook
    serviceAccountName: cert-manager-webhook
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-9657m
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:58Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:58Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:29:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f60e25f3ca9dddc430ade42179a757868cf2264e52682a003fb2fd52df7b8efc
      image: quay.io/jetstack/cert-manager-webhook:v1.14.4
      imageID: quay.io/jetstack/cert-manager-webhook@sha256:11f7e7c462da3c0329e0a1e695a7bd37d6b3c28312d4edd4cc8d36f70ecbfa63
      lastState: {}
      name: cert-manager-webhook
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:29:33Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.15
    podIPs:
    - ip: 192.168.0.15
    qosClass: BestEffort
    startTime: "2024-04-01T04:29:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      component.meshery.io/id: 0253ba12-434a-4eae-9080-460d1d7894b6
      design.meshery.io/version: 0.0.1
    creationTimestamp: "2025-01-10T16:29:21Z"
    labels:
      design.meshery.io/id: c80a3f4e-e764-40b5-84ab-2c9aa0776ffb
    name: pod-es
    namespace: default
    resourceVersion: "69301513"
    uid: be0469ef-d5b1-422d-b489-901f12f3d1b4
  spec:
    containers:
    - image: nginx/nginx
      imagePullPolicy: Always
      name: test
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dd4bf
        readOnly: true
    - image: nginx.io
      imagePullPolicy: Always
      name: nginx
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dd4bf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dd4bf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-10T16:29:22Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-10T16:29:21Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-10T16:29:21Z"
      message: 'containers with unready status: [test nginx]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-10T16:29:21Z"
      message: 'containers with unready status: [test nginx]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-10T16:29:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: nginx.io
      imageID: ""
      lastState: {}
      name: nginx
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          message: Back-off pulling image "nginx.io"
          reason: ImagePullBackOff
    - image: nginx/nginx
      imageID: ""
      lastState: {}
      name: test
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          message: Back-off pulling image "nginx/nginx"
          reason: ImagePullBackOff
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Pending
    podIP: 192.168.0.27
    podIPs:
    - ip: 192.168.0.27
    qosClass: BestEffort
    startTime: "2025-01-10T16:29:21Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T15:29:56Z"
    generateName: emissary-apiext-7d468cdc87-
    labels:
      app.kubernetes.io/instance: emissary-apiext
      app.kubernetes.io/managed-by: kubectl_apply_-f_aes-apiext.yaml
      app.kubernetes.io/name: emissary-apiext
      app.kubernetes.io/part-of: emissary-apiext
      pod-template-hash: 7d468cdc87
    name: emissary-apiext-7d468cdc87-ghrvn
    namespace: emissary-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-apiext-7d468cdc87
      uid: f02169bb-21b6-4395-bebe-002b8cf4509c
    resourceVersion: "47870822"
    uid: d224ba3a-7783-4906-a1ef-3c54e4599d49
  spec:
    containers:
    - args:
      - --crd-label-selector
      - app.kubernetes.io/part-of=emissary-apiext
      command:
      - apiext
      - emissary-apiext
      image: docker.io/datawire/aes:3.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /probes/live
          port: 8080
          scheme: HTTP
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      name: emissary-apiext
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8443
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /probes/ready
          port: 8080
          scheme: HTTP
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      startupProbe:
        failureThreshold: 10
        httpGet:
          path: /probes/live
          port: 8080
          scheme: HTTP
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zxzgm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: emissary-apiext
    serviceAccountName: emissary-apiext
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-zxzgm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T15:29:57Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T15:29:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T15:29:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4d6abc6d01e36706ad17263657daf6d3eea7afe31d26501d392db74316aac9c9
      image: docker.io/datawire/aes:3.11.1
      imageID: docker.io/datawire/aes@sha256:95ec30b3c73256006896daa426d3cb0a21ca08e8cbb84244145140006242bbdb
      lastState: {}
      name: emissary-apiext
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-10-01T15:29:57Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.20
    podIPs:
    - ip: 192.168.0.20
    qosClass: BestEffort
    startTime: "2024-10-01T15:29:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      sidecar.istio.io/inject: "false"
    creationTimestamp: "2024-11-27T01:51:52Z"
    generateName: cm-acme-http-solver-
    labels:
      acme.cert-manager.io/http-domain: "2939030417"
      acme.cert-manager.io/http-token: "1249119978"
      acme.cert-manager.io/http01-solver: "true"
    name: cm-acme-http-solver-s4qmc
    namespace: emissary
    ownerReferences:
    - apiVersion: acme.cert-manager.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Challenge
      name: certs-staging-playground-5-1341959213-421573756
      uid: dc39fecd-c983-4f45-9aec-a7803811d7e4
    resourceVersion: "53251993"
    uid: c8bb28bf-0b8a-4cd2-aa46-a3df14ce2cf7
  spec:
    automountServiceAccountToken: false
    containers:
    - args:
      - --listen-port=8089
      - --domain=staging-playground.meshery.io
      - --token=Ipel2z0u4V_IALhnKzhhYv_Ko3L_amacLTDL_CyLQKY
      - --key=Ipel2z0u4V_IALhnKzhhYv_Ko3L_amacLTDL_CyLQKY.ODvwH1EwJZU7B64Id9Z2YiGVrUEUhMJcCTqROrNpUrk
      image: quay.io/jetstack/cert-manager-acmesolver:v1.14.4
      imagePullPolicy: IfNotPresent
      name: acmesolver
      ports:
      - containerPort: 8089
        name: http
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 64Mi
        requests:
          cpu: 10m
          memory: 64Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
    dnsPolicy: ClusterFirst
    enableServiceLinks: false
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-27T01:51:54Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-27T01:51:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-27T01:51:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-27T01:51:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-27T01:51:52Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://eb8096544a8a78b71ae3287ae11252fa7ea1025ec418692934ef89ef6943a27b
      image: quay.io/jetstack/cert-manager-acmesolver:v1.14.4
      imageID: quay.io/jetstack/cert-manager-acmesolver@sha256:83aade427ff5d338380aa0b5d0e65a9f1ef9db09215311eb64b94f833e75b864
      lastState: {}
      name: acmesolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-27T01:51:53Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.6
    podIPs:
    - ip: 192.168.0.6
    qosClass: Burstable
    startTime: "2024-11-27T01:51:52Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
    creationTimestamp: "2024-04-01T04:11:02Z"
    generateName: emissary-ingress-5fccb6758d-
    labels:
      app.kubernetes.io/instance: emissary-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: emissary-ingress
      app.kubernetes.io/part-of: emissary-ingress
      helm.sh/chart: emissary-ingress-8.9.1
      pod-template-hash: 5fccb6758d
      product: aes
      profile: main
    name: emissary-ingress-5fccb6758d-2t6sh
    namespace: emissary
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-ingress-5fccb6758d
      uid: d56ae810-81d2-43b7-a8f8-422777cfaf9d
    resourceVersion: "47870709"
    uid: e7d3efdf-0853-49dc-9a1a-f45e92f0e3aa
  spec:
    containers:
    - env:
      - name: AMBASSADOR_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: AGENT_CONFIG_RESOURCE_NAME
        value: emissary-ingress-agent-cloud-token
      image: docker.io/emissaryingress/emissary:3.9.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ambassador/v0/check_alive
          port: admin
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      name: emissary-ingress
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 8443
        name: https
        protocol: TCP
      - containerPort: 8877
        name: admin
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ambassador/v0/check_ready
          port: admin
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 600Mi
        requests:
          cpu: 200m
          memory: 300Mi
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/ambassador-pod-info
        name: ambassador-pod-info
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-frqqj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - args:
      - |
        deployment_name="emissary-apiext"
        deployment_namespace="emissary-system"
        while true; do
          echo "checking if deployment/$deployment_name in namespace: $deployment_namespace exists."
          if kubectl get deployment "$deployment_name" -n $deployment_namespace > /dev/null 2>&1; then
            echo "$deployment_name.$deployment_namespace exists."
            echo "checking if $deployment_name.$deployment_namespace is fully available..."
            kubectl wait --for=condition=available deployment/"$deployment_name" -n $deployment_namespace --timeout=5m
            if [ $? -eq 0 ]; then
              echo "$deployment_name.$deployment_namespace is available"
              while true; do
              desired_replicas=$(kubectl get deployment $deployment_name -n $deployment_namespace -o jsonpath='{.spec.replicas}')
              current_replicas=$(kubectl get deployment $deployment_name -n $deployment_namespace -o jsonpath='{.status.replicas}')
              if [[ $current_replicas != $desired_replicas ]]; then
                echo "$deployment_name.$deployment_namespace is in the process of restarting. Have: $current_replicas, want $desired_replicas"
                sleep 3
              else
                echo "$deployment_name.$deployment_namespace is fully ready and not currently restarting.  Have: $current_replicas, want $desired_replicas"
                break
              fi
              done
              break
            else
              echo "$deployment_name.$deployment_namespace did not become available within the timeout"
            fi
          else
            echo "$deployment_name.$deployment_namespace does not exist yet. Waiting..."
            sleep 3
          fi
        done
      command:
      - /bin/sh
      - -c
      image: istio/kubectl:1.5.10
      imagePullPolicy: IfNotPresent
      name: wait-for-apiext
      resources: {}
      securityContext:
        runAsUser: 8888
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-frqqj
        readOnly: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsUser: 8888
    serviceAccount: emissary-ingress
    serviceAccountName: emissary-ingress
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - downwardAPI:
        defaultMode: 420
        items:
        - fieldRef:
            apiVersion: v1
            fieldPath: metadata.labels
          path: labels
      name: ambassador-pod-info
    - name: kube-api-access-frqqj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:03Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:04Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://310fd1fe7deaadaeb6eb7719c5d26947f901771a16b1f0c56e5df0fb9fe23c12
      image: docker.io/emissaryingress/emissary:3.9.1
      imageID: docker.io/emissaryingress/emissary@sha256:17374fc250f8194a156dd16db9b58359cd170b5e18de6dc213b4830f47f58ce8
      lastState: {}
      name: emissary-ingress
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:11:04Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://c2db955aa10edfd1aa0f05309e9807433652b771e91c1e816c259cc1b9912fb0
      image: docker.io/istio/kubectl:1.5.10
      imageID: docker.io/istio/kubectl@sha256:dbb7726d1bf0229053ebeaf62be3a07025d61b5f4ccc9cef94e0bd9416ddd4cd
      lastState: {}
      name: wait-for-apiext
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c2db955aa10edfd1aa0f05309e9807433652b771e91c1e816c259cc1b9912fb0
          exitCode: 0
          finishedAt: "2024-04-01T04:11:03Z"
          reason: Completed
          startedAt: "2024-04-01T04:11:03Z"
    phase: Running
    podIP: 192.168.0.12
    podIPs:
    - ip: 192.168.0.12
    qosClass: Burstable
    startTime: "2024-04-01T04:11:02Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T04:11:02Z"
    generateName: emissary-ingress-agent-7f6bb847d8-
    labels:
      app.kubernetes.io/instance: emissary-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: emissary-ingress-agent
      app.kubernetes.io/part-of: emissary-ingress
      helm.sh/chart: emissary-ingress-8.9.1
      pod-template-hash: 7f6bb847d8
      product: aes
    name: emissary-ingress-agent-7f6bb847d8-k5zk8
    namespace: emissary
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: emissary-ingress-agent-7f6bb847d8
      uid: 27335631-68a8-4de1-887b-037f6762a494
    resourceVersion: "46089061"
    uid: 40324e94-f285-4891-9b41-d4825f056690
  spec:
    containers:
    - env:
      - name: AGENT_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: AGENT_CONFIG_RESOURCE_NAME
        value: emissary-ingress-agent-cloud-token
      - name: RPC_CONNECTION_ADDRESS
        value: https://app.getambassador.io/
      - name: AES_SNAPSHOT_URL
        value: http://emissary-ingress-admin.emissary:8005/snapshot-external
      - name: AES_REPORT_DIAGNOSTICS_TO_CLOUD
        value: "true"
      - name: AES_DIAGNOSTICS_URL
        value: http://emissary-ingress-admin.emissary:8877/ambassador/v0/diag/?json=true
      image: docker.io/ambassador/ambassador-agent:1.0.14
      imagePullPolicy: IfNotPresent
      name: agent
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5d2g6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: emissary-ingress-agent
    serviceAccountName: emissary-ingress-agent
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-5d2g6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:03Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:03Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:03Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:11:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c237c7ab2d696f4eb61179e1d1237c1dec8ba4f84ecebc053bb6cf42c3513e61
      image: docker.io/ambassador/ambassador-agent:1.0.14
      imageID: docker.io/ambassador/ambassador-agent@sha256:23379686e04f803d1a21afc5b0013133216b2f4659868b9a381e38373026eda2
      lastState: {}
      name: agent
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:11:03Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.9
    podIPs:
    - ip: 192.168.0.9
    qosClass: BestEffort
    startTime: "2024-04-01T04:11:02Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-09T04:07:12Z"
    generateName: ingress-nginx-admission-create-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.8.1
      batch.kubernetes.io/controller-uid: 4ae861ee-798b-4b45-92f3-82fad510c9eb
      batch.kubernetes.io/job-name: ingress-nginx-admission-create
      controller-uid: 4ae861ee-798b-4b45-92f3-82fad510c9eb
      job-name: ingress-nginx-admission-create
    name: ingress-nginx-admission-create-zx2dc
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-create
      uid: 4ae861ee-798b-4b45-92f3-82fad510c9eb
    resourceVersion: "48624604"
    uid: 330fa077-863b-48b5-bbcd-04fbb185a82d
  spec:
    containers:
    - args:
      - create
      - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
      - --namespace=$(POD_NAMESPACE)
      - --secret-name=ingress-nginx-admission
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20230407@sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b
      imagePullPolicy: IfNotPresent
      name: create
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kdp5z
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-kdp5z
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:17Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:15Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:15Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://47f83148e7edd5bc8864a3ab9e6a2bcf6032dcaa2c3c2212fb883bd4ab2d10a5
      image: sha256:7e7451bb70423d31bdadcf0a71a3107b64858eccd7827d066234650b5e7b36b0
      imageID: registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b
      lastState: {}
      name: create
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://47f83148e7edd5bc8864a3ab9e6a2bcf6032dcaa2c3c2212fb883bd4ab2d10a5
          exitCode: 0
          finishedAt: "2024-11-09T04:07:14Z"
          reason: Completed
          startedAt: "2024-11-09T04:07:14Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Succeeded
    podIP: 192.168.0.30
    podIPs:
    - ip: 192.168.0.30
    qosClass: BestEffort
    startTime: "2024-11-09T04:07:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-09T04:07:12Z"
    generateName: ingress-nginx-admission-patch-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.8.1
      batch.kubernetes.io/controller-uid: c3aef92d-c025-42d5-bed8-a58d4dbe7e6b
      batch.kubernetes.io/job-name: ingress-nginx-admission-patch
      controller-uid: c3aef92d-c025-42d5-bed8-a58d4dbe7e6b
      job-name: ingress-nginx-admission-patch
    name: ingress-nginx-admission-patch-n6s9c
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-patch
      uid: c3aef92d-c025-42d5-bed8-a58d4dbe7e6b
    resourceVersion: "48624598"
    uid: 620ce2e7-7df0-4b35-a4df-023e0b076063
  spec:
    containers:
    - args:
      - patch
      - --webhook-name=ingress-nginx-admission
      - --namespace=$(POD_NAMESPACE)
      - --patch-mutating=false
      - --secret-name=ingress-nginx-admission
      - --patch-failure-policy=Fail
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20230407@sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b
      imagePullPolicy: IfNotPresent
      name: patch
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8h6wh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-8h6wh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:16Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e6510bf65c5e0fd00f0eb39bfc588d7a40eaeb3190cd453f8067a38b68a00ca6
      image: sha256:7e7451bb70423d31bdadcf0a71a3107b64858eccd7827d066234650b5e7b36b0
      imageID: registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b
      lastState: {}
      name: patch
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://e6510bf65c5e0fd00f0eb39bfc588d7a40eaeb3190cd453f8067a38b68a00ca6
          exitCode: 0
          finishedAt: "2024-11-09T04:07:15Z"
          reason: Completed
          startedAt: "2024-11-09T04:07:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Succeeded
    podIP: 192.168.0.32
    podIPs:
    - ip: 192.168.0.32
    qosClass: BestEffort
    startTime: "2024-11-09T04:07:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-09T04:07:12Z"
    generateName: ingress-nginx-controller-568fb54f96-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.8.1
      pod-template-hash: 568fb54f96
    name: ingress-nginx-controller-568fb54f96-w4qt9
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ingress-nginx-controller-568fb54f96
      uid: 49558274-890d-4bf5-bbb7-a5e0c4bc3db7
    resourceVersion: "48624676"
    uid: b2ffa6e2-412c-4cf5-b16d-a6c94326b506
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller
      - --election-id=ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --ingress-class=nginx
      - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.8.1@sha256:e5c4824e7375fcf2a393e1c03c293b69759af37a9ca6abdb91b13d78a93da8bd
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        name: https
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        runAsUser: 101
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cd5jd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ingress-nginx
    serviceAccountName: ingress-nginx
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: ingress-nginx-admission
    - name: kube-api-access-cd5jd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:20Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-09T04:07:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://969b1570530d47c51226038aefc3828f43ac43141fb712c3be4b66933389af41
      image: sha256:825aff16c20cc2c6039fce49bafaa0f510de0f9238da475f3de949adadb9be7f
      imageID: registry.k8s.io/ingress-nginx/controller@sha256:e5c4824e7375fcf2a393e1c03c293b69759af37a9ca6abdb91b13d78a93da8bd
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-09T04:07:20Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.33
    podIPs:
    - ip: 192.168.0.33
    qosClass: Burstable
    startTime: "2024-11-09T04:07:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 68c00ea91b7ba5c04efc55555ef2307f52aaf738b04e9665e91bb756c8f32b22
      checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2025-01-24T20:20:40Z"
    generateName: grafana-58856dc744-
    labels:
      app.kubernetes.io/instance: grafana
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 11.3.1
      helm.sh/chart: grafana-8.6.3
      pod-template-hash: 58856dc744
      sidecar.istio.io/inject: "false"
    name: grafana-58856dc744-287b5
    namespace: istio-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: grafana-58856dc744
      uid: 4ae114e9-8b5b-4bfa-ae77-1680d9fe1ecf
    resourceVersion: "65979964"
    uid: 49bd1b76-fdcd-4ecb-bd8a-0d75bdc3e61d
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      - name: GF_AUTH_ANONYMOUS_ENABLED
        value: "true"
      - name: GF_AUTH_ANONYMOUS_ORG_ROLE
        value: Admin
      - name: GF_AUTH_BASIC_ENABLED
        value: "false"
      - name: GF_SECURITY_ADMIN_PASSWORD
        value: admin
      - name: GF_SECURITY_ADMIN_USER
        value: admin
      image: docker.io/grafana/grafana:11.3.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /var/lib/grafana/dashboards/istio
        name: dashboards-istio
      - mountPath: /var/lib/grafana/dashboards/istio-services
        name: dashboards-istio-services
      - mountPath: /etc/grafana/provisioning/datasources/datasources.yaml
        name: config
        subPath: datasources.yaml
      - mountPath: /etc/grafana/provisioning/dashboards/dashboardproviders.yaml
        name: config
        subPath: dashboardproviders.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mgkqk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: grafana
    serviceAccountName: grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: grafana
      name: config
    - configMap:
        defaultMode: 420
        name: istio-grafana-dashboards
      name: dashboards-istio
    - configMap:
        defaultMode: 420
        name: istio-services-grafana-dashboards
      name: dashboards-istio-services
    - emptyDir: {}
      name: storage
    - name: kube-api-access-mgkqk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T20:20:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T20:20:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T20:20:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T20:20:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T20:20:40Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1e1a5f49f1bbb1e863d6e5d92cafb1eee26ea3dfc7efabee2093d07c63e26f1b
      image: docker.io/grafana/grafana:11.3.1
      imageID: docker.io/grafana/grafana@sha256:fa801ab6e1ae035135309580891e09f7eb94d1abdbd2106bdc288030b028158c
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-24T20:20:46Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.29
    podIPs:
    - ip: 192.168.0.29
    qosClass: BestEffort
    startTime: "2025-01-24T20:20:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-01-24T19:57:53Z"
    generateName: prometheus-54b98b699b-
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: prometheus
      app.kubernetes.io/version: v3.1.0
      helm.sh/chart: prometheus-26.1.0
      pod-template-hash: 54b98b699b
      sidecar.istio.io/inject: "false"
    name: prometheus-54b98b699b-hm9dt
    namespace: istio-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-54b98b699b
      uid: e6959d58-03e1-47ab-9660-2538564f4c73
    resourceVersion: "65976400"
    uid: 6a34691d-e1b6-4ede-a496-23f83593333d
  spec:
    containers:
    - args:
      - --watched-dir=/etc/config
      - --listen-address=0.0.0.0:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      image: ghcr.io/prometheus-operator/prometheus-config-reloader:v0.78.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: prometheus-server-configmap-reload
      ports:
      - containerPort: 8080
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qftv8
        readOnly: true
    - args:
      - --storage.tsdb.retention.time=15d
      - --config.file=/etc/config/prometheus.yml
      - --storage.tsdb.path=/data
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --web.enable-lifecycle
      image: prom/prometheus:v3.1.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/healthy
          port: 9090
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 10
      name: prometheus-server
      ports:
      - containerPort: 9090
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: 9090
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: config-volume
      - mountPath: /data
        name: storage-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qftv8
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: prometheus
    serviceAccountName: prometheus
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: prometheus
      name: config-volume
    - emptyDir: {}
      name: storage-volume
    - name: kube-api-access-qftv8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T19:58:00Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T19:57:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T19:58:01Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T19:58:01Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-24T19:57:53Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://2852653a1d1c6964b22c10461b4c6dd5c307cb4dcd4596098364ae7860f589f2
      image: docker.io/prom/prometheus:v3.1.0
      imageID: docker.io/prom/prometheus@sha256:6559acbd5d770b15bb3c954629ce190ac3cbbdb2b7f1c30f0385c4e05104e218
      lastState: {}
      name: prometheus-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-24T19:57:59Z"
    - containerID: containerd://4049215ab199c7f8fba63b6dbe87edb3c6ed590c0936e97a60ffc27cf0679381
      image: ghcr.io/prometheus-operator/prometheus-config-reloader:v0.78.2
      imageID: ghcr.io/prometheus-operator/prometheus-config-reloader@sha256:944b2c67345c2dd9fafc4cddbf389cb09f930f9e83c8d06e90147076223a9e56
      lastState: {}
      name: prometheus-server-configmap-reload
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-24T19:57:55Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.28
    podIPs:
    - ip: 192.168.0.28
    qosClass: BestEffort
    startTime: "2025-01-24T19:57:53Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-06T05:51:20Z"
    generateName: coredns-76f75df574-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 76f75df574
    name: coredns-76f75df574-8jzp5
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-76f75df574
      uid: d3ef6fa9-febf-4972-ab5d-d1cf83b38b18
    resourceVersion: "47871071"
    uid: bc8c4ffd-8db5-44e9-911c-e3664b42be52
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kwcfc
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-kwcfc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4d3cb49c2b33a100cd7a149d8c8183e6d7dbb0055afa0391473b6d5b8489154c
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-06T05:51:21Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.4
    podIPs:
    - ip: 192.168.0.4
    qosClass: Burstable
    startTime: "2024-11-06T05:51:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-06T05:51:16Z"
    generateName: coredns-76f75df574-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 76f75df574
    name: coredns-76f75df574-ws7lc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-76f75df574
      uid: d3ef6fa9-febf-4972-ab5d-d1cf83b38b18
    resourceVersion: "47871031"
    uid: 48c87cbb-6e58-4325-bde0-395549d537e0
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tfdpp
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-tfdpp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://11ed66da236799f616ec53fba97c6adc08ac954274c25b5980e5a02feb328d3f
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-06T05:51:17Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.3
    podIPs:
    - ip: 192.168.0.3
    qosClass: Burstable
    startTime: "2024-11-06T05:51:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://10.65.18.5:2379
      kubernetes.io/config.hash: 955287bf933cf05484fc77fae916732f
      kubernetes.io/config.mirror: 955287bf933cf05484fc77fae916732f
      kubernetes.io/config.seen: "2024-04-01T03:46:15.019054642Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-04-01T03:46:18Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-c3-medium-x86-03-meshery
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: c3-medium-x86-03-meshery
      uid: 091022f9-bbba-4427-ada7-00e6e0deb886
    resourceVersion: "47870880"
    uid: ca0e8af2-60e8-4a46-a9f6-3c4c9db56a08
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://10.65.18.5:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://10.65.18.5:2380
      - --initial-cluster=c3-medium-x86-03-meshery=https://10.65.18.5:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://10.65.18.5:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://10.65.18.5:2380
      - --name=c3-medium-x86-03-meshery
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.12-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:59Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:59Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4dc1ed9f096c6d3fdee0fff4ea64ac51770d4dd122ff28c31ba44bece915a8d0
      image: registry.k8s.io/etcd:3.5.12-0
      imageID: registry.k8s.io/etcd@sha256:44a8e24dcbba3470ee1fee21d5e88d128c936e9b55d4bc51fbef8086f8ed123b
      lastState: {}
      name: etcd
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:46:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-11-06T05:50:52Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 10.65.18.5:6443
      kubernetes.io/config.hash: 4d2df7298a3f73eacea0b299825c7b7c
      kubernetes.io/config.mirror: 4d2df7298a3f73eacea0b299825c7b7c
      kubernetes.io/config.seen: "2024-04-01T03:46:19.804617548Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-04-01T03:46:19Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-c3-medium-x86-03-meshery
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: c3-medium-x86-03-meshery
      uid: 091022f9-bbba-4427-ada7-00e6e0deb886
    resourceVersion: "68535711"
    uid: 572a6dff-c00d-46f3-b02b-c7c818a0f805
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=10.65.18.5
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.29.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 10.65.18.5
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 10.65.18.5
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 10.65.18.5
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://53e05dfdf821fbc4696055c3c7b883e65de1eaca2e709b889a301985f934c973
      image: registry.k8s.io/kube-apiserver:v1.29.3
      imageID: registry.k8s.io/kube-apiserver@sha256:ebd35bc7ef24672c5c50ffccb21f71307a82d4fb20c0ecb6d3d27b28b69e0e3c
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:46:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-11-06T05:50:52Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: c24568d59745185f80c6701ae6d46b9a
      kubernetes.io/config.mirror: c24568d59745185f80c6701ae6d46b9a
      kubernetes.io/config.seen: "2024-04-01T03:46:19.804619061Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-04-01T03:46:19Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-c3-medium-x86-03-meshery
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: c3-medium-x86-03-meshery
      uid: 091022f9-bbba-4427-ada7-00e6e0deb886
    resourceVersion: "47870821"
    uid: 14ea382a-d9bb-45b0-ad37-b142e7b3e3e2
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=kubernetes
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.29.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://a2f261d3b3442839e532124759ff17108f8f3741f085d298c1876869d7f58c20
      image: registry.k8s.io/kube-controller-manager:v1.29.3
      imageID: registry.k8s.io/kube-controller-manager@sha256:5a7968649f8aee83d5a2d75d6d377ba2680df25b0b97b3be12fa10f15ad67104
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:46:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-11-06T05:50:52Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T03:46:34Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: "7659797656"
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-95kdh
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: e13a2b45-a00d-48fb-b126-6712c3236b8a
    resourceVersion: "401"
    uid: 791e87b1-086d-4f5b-8859-1eba5ab70bb8
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - c3-medium-x86-03-meshery
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.29.3
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dvv2v
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-dvv2v
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:46:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:46:34Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:46:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:46:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:46:34Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7011670082495a1a27e459203782b6ac9648fc11559415f66259cf48289ce4e5
      image: registry.k8s.io/kube-proxy:v1.29.3
      imageID: registry.k8s.io/kube-proxy@sha256:fa87cba052adcb992bd59bd1304115c6f3b3fb370407805ba52af3d9ff3f0863
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:46:34Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: BestEffort
    startTime: "2024-04-01T03:46:34Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7d383f77e4929bf2ab3c9645efe57bdf
      kubernetes.io/config.mirror: 7d383f77e4929bf2ab3c9645efe57bdf
      kubernetes.io/config.seen: "2024-04-01T03:46:15.019060393Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-04-01T03:46:18Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-c3-medium-x86-03-meshery
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: c3-medium-x86-03-meshery
      uid: 091022f9-bbba-4427-ada7-00e6e0deb886
    resourceVersion: "47870713"
    uid: 7d2ed284-f97e-474a-8de0-fdee8a12ba53
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: registry.k8s.io/kube-scheduler:v1.29.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:52Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://a69b0f95e0921536fd5c528783311c0ea3bd03d02e25c9d83577446a87b6e3b6
      image: registry.k8s.io/kube-scheduler:v1.29.3
      imageID: registry.k8s.io/kube-scheduler@sha256:6fb91d791db6d62f6b1ac9dbed23fdb597335550d99ff8333d53c4136e889b3a
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:46:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-11-06T05:50:52Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-11T19:35:31Z"
    generateName: metrics-server-84d85ccf8c-
    labels:
      k8s-app: metrics-server
      pod-template-hash: 84d85ccf8c
    name: metrics-server-84d85ccf8c-m4k2g
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-84d85ccf8c
      uid: 070e5ba3-7140-44ba-a400-2edd3d11d8df
    resourceVersion: "49338043"
    uid: 8fa37284-370c-4c06-adf0-8fd105e1caef
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=4443
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --kubelet-insecure-tls
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 4443
        hostPort: 4443
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fsmpj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-fsmpj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-11T19:35:32Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-11T19:35:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-11T19:35:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-11T19:35:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-11T19:35:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://45bea74e77b3be51e3787ce096a0af31ff2ac2299b0ccd1c466b2c10395b392d
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imageID: registry.k8s.io/metrics-server/metrics-server@sha256:ffcb2bf004d6aa0a17d90e0247cf94f2865c8901dcab4427034c341951c239f9
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-11T19:35:31Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-11-11T19:35:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T03:55:12Z"
    generateName: weave-net-
    labels:
      controller-revision-hash: 778d789685
      name: weave-net
      pod-template-generation: "1"
    name: weave-net-x89sr
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: weave-net
      uid: 532bcd57-b9e9-4ce8-882f-82fba72dac48
    resourceVersion: "47870770"
    uid: 755bc88d-da60-4b36-be5f-2570e298dd96
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - c3-medium-x86-03-meshery
    containers:
    - command:
      - /home/weave/launch.sh
      env:
      - name: INIT_CONTAINER
        value: "true"
      - name: HOSTNAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: IPALLOC_RANGE
        value: 192.168.0.0/16
      image: weaveworks/weave-kube:latest
      imagePullPolicy: Always
      name: weave
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 127.0.0.1
          path: /status
          port: 6784
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 50m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /weavedb
        name: weavedb
      - mountPath: /host/var/lib/dbus
        name: dbus
        readOnly: true
      - mountPath: /host/etc/machine-id
        name: cni-machine-id
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9px8d
        readOnly: true
    - env:
      - name: HOSTNAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: weaveworks/weave-npc:latest
      imagePullPolicy: Always
      name: weave-npc
      resources:
        requests:
          cpu: 50m
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9px8d
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /home/weave/init.sh
      image: weaveworks/weave-kube:latest
      imagePullPolicy: Always
      name: weave-init
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt
        name: cni-bin
      - mountPath: /host/home
        name: cni-bin2
      - mountPath: /host/etc
        name: cni-conf
      - mountPath: /lib/modules
        name: lib-modules
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9px8d
        readOnly: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seLinuxOptions: {}
    serviceAccount: weave-net
    serviceAccountName: weave-net
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/weave
        type: ""
      name: weavedb
    - hostPath:
        path: /opt
        type: ""
      name: cni-bin
    - hostPath:
        path: /home
        type: ""
      name: cni-bin2
    - hostPath:
        path: /etc
        type: ""
      name: cni-conf
    - hostPath:
        path: /etc/machine-id
        type: ""
      name: cni-machine-id
    - hostPath:
        path: /var/lib/dbus
        type: ""
      name: dbus
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-9px8d
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:55:13Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:55:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T03:55:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://510ee84f9ae98ac23324f9dda8f39302a8b058c2aa53249c7a4286072ac8d8be
      image: docker.io/weaveworks/weave-kube:latest
      imageID: docker.io/weaveworks/weave-kube@sha256:35827a9c549c095f0e9d1cf8b35d8f27ae2c76e31bc6f7f3c0bc95911d5accea
      lastState: {}
      name: weave
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:55:15Z"
    - containerID: containerd://23e79a24fd9019df22db785fb2dc6d01ff4f791d30c92085442fb37acf1ea41d
      image: docker.io/weaveworks/weave-npc:latest
      imageID: docker.io/weaveworks/weave-npc@sha256:062832fd25b5e9e16650e618f26bba1409a7b3bf2c3903e1b369d788abc63aef
      lastState: {}
      name: weave-npc
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T03:55:16Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://3ed3c7c1e4ced12f45ba9b96cb7a9201afcb1ef08a44796b0c19028b1c82d048
      image: docker.io/weaveworks/weave-kube:latest
      imageID: docker.io/weaveworks/weave-kube@sha256:35827a9c549c095f0e9d1cf8b35d8f27ae2c76e31bc6f7f3c0bc95911d5accea
      lastState: {}
      name: weave-init
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://3ed3c7c1e4ced12f45ba9b96cb7a9201afcb1ef08a44796b0c19028b1c82d048
          exitCode: 0
          finishedAt: "2024-04-01T03:55:14Z"
          reason: Completed
          startedAt: "2024-04-01T03:55:13Z"
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: Burstable
    startTime: "2024-04-01T03:55:12Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-29T12:30:38Z"
    generateName: local-path-provisioner-6d9d9b57c9-
    labels:
      app: local-path-provisioner
      pod-template-hash: 6d9d9b57c9
    name: local-path-provisioner-6d9d9b57c9-wzst7
    namespace: local-path-storage
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: local-path-provisioner-6d9d9b57c9
      uid: 45ee6149-05a5-4e53-b85b-15bf97984064
    resourceVersion: "5900390"
    uid: eac003fe-128b-4cd3-871c-274e3c045fc7
  spec:
    containers:
    - command:
      - local-path-provisioner
      - --debug
      - start
      - --config
      - /etc/config/config.json
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/local-path-provisioner:v0.0.26
      imagePullPolicy: IfNotPresent
      name: local-path-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9v6cf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: local-path-provisioner-service-account
    serviceAccountName: local-path-provisioner-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: local-path-config
      name: config-volume
    - name: kube-api-access-9v6cf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-29T12:30:40Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-29T12:30:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-04-29T12:30:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-04-29T12:30:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-29T12:30:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3f9c0f9c8502a20eec5d84d1d52c71dc4c4621feb12fbd35b0e2c83733e4158f
      image: docker.io/rancher/local-path-provisioner:v0.0.26
      imageID: docker.io/rancher/local-path-provisioner@sha256:aee53cadc62bd023911e7f077877d047c5b3c269f9bba25724d558654f43cea0
      lastState: {}
      name: local-path-provisioner
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-29T12:30:40Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.18
    podIPs:
    - ip: 192.168.0.18
    qosClass: BestEffort
    startTime: "2024-04-29T12:30:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-10-28T02:54:14Z"
    creationTimestamp: "2025-02-07T07:08:41Z"
    generateName: meshery-77749b8b78-
    labels:
      app: meshery
      pod-template-hash: 77749b8b78
    name: meshery-77749b8b78-vz9df
    namespace: meshery-extensions
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: meshery-77749b8b78
      uid: 7c0c3bf0-5413-46f4-9f78-183e019faf70
    resourceVersion: "68980190"
    uid: 873341b0-b5b0-45c5-9d9c-82d20125877f
  spec:
    containers:
    - env:
      - name: PROVIDER_BASE_URLS
        value: https://cloud.layer5.io
      - name: PROVIDER
        value: Meshery
      - name: PLAYGROUND
        value: "true"
      - name: DISABLE_OPERATOR
        value: "true"
      - name: CAPABILITIES
      image: layer5/meshery:kanvas-v0.8.27
      imagePullPolicy: Always
      name: meshery
      ports:
      - containerPort: 8080
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-swknr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-swknr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T07:09:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T07:08:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T07:09:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T07:09:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T07:08:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://da1d457f155055b1e5e4fa19fc76e55a559455d9c1cc8a85102054e9e316c1c9
      image: docker.io/layer5/meshery:kanvas-v0.8.27
      imageID: docker.io/layer5/meshery@sha256:b5d129ae22f01236e79642d1e22699381c39430d01670905d1679572f9dacbce
      lastState: {}
      name: meshery
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-02-07T07:09:05Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.26
    podIPs:
    - ip: 192.168.0.26
    qosClass: BestEffort
    startTime: "2025-02-07T07:08:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-01-09T22:47:27Z"
    generateName: meshery-6487b554bd-
    labels:
      app.kubernetes.io/instance: meshery
      app.kubernetes.io/name: meshery
      pod-template-hash: 6487b554bd
    name: meshery-6487b554bd-zrtz5
    namespace: meshery
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: meshery-6487b554bd
      uid: 19081267-fb9a-4e34-a4d4-2f1490fa11f7
    resourceVersion: "62656708"
    uid: fd79b222-4c7c-429f-be5f-491a524cf5f3
  spec:
    containers:
    - env:
      - name: ADAPTER_URLS
        value: meshery-istio:10000 meshery-linkerd:10001 meshery-consul:10002 meshery-kuma:10007
          meshery-nginx-sm:10010 meshery-nsm:10004 meshery-app-mesh:10005 meshery-traefik-mesh:10006
          meshery-cilium:10012
      - name: EVENT
        value: mesheryLocal
      - name: KEYS_PATH
        value: ../../server/permissions/keys.csv
      - name: MESHERY_SERVER_CALLBACK_URL
      - name: PROVIDER
        value: Meshery
      - name: PROVIDER_BASE_URLS
        value: https://cloud.layer5.io
      image: layer5/meshery:edge-latest
      imagePullPolicy: Always
      name: meshery
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      resources: {}
      securityContext: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dx5lj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: meshery-server
    serviceAccountName: meshery-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dx5lj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:49Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:27Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:49Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:49Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:27Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://adc39c36d8310e08aa1b625366566e1464bf65064f6f24f1ea3d6d78cc82b8ce
      image: docker.io/layer5/meshery:edge-latest
      imageID: docker.io/layer5/meshery@sha256:97702282aad7f332045f4997022fcb916d328b5da5c52a87e47702ba13455f27
      lastState: {}
      name: meshery
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:48Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.13
    podIPs:
    - ip: 192.168.0.13
    qosClass: BestEffort
    startTime: "2025-01-09T22:47:27Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      meshery/component-type: management-plane
      prometheus.io/path: /metrics
      prometheus.io/port: "7777"
      prometheus.io/scrape: "true"
    creationTimestamp: "2025-01-09T22:47:50Z"
    generateName: meshery-broker-
    labels:
      app: meshery
      apps.kubernetes.io/pod-index: "0"
      component: broker
      controller-revision-hash: meshery-broker-56cff9c4f6
      statefulset.kubernetes.io/pod-name: meshery-broker-0
    name: meshery-broker-0
    namespace: meshery
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: meshery-broker
      uid: a59426f9-344b-4ecd-9fc2-24b055dd564a
    resourceVersion: "62656830"
    uid: 89b88eff-96bf-4879-84af-c8923d511b7b
  spec:
    containers:
    - command:
      - nats-server
      - --config
      - /etc/nats-config/nats.conf
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: CLUSTER_ADVERTISE
        value: $(POD_NAME).meshery-nats.$(POD_NAMESPACE).svc
      image: nats:2.8.2-alpine3.15
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/sh
            - -c
            - nats-server -sl=ldm=/var/run/nats/nats.pid && /bin/sleep 60
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8222
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: nats
      ports:
      - containerPort: 4222
        name: client
        protocol: TCP
      - containerPort: 6222
        name: cluster
        protocol: TCP
      - containerPort: 7422
        name: leafnodes
        protocol: TCP
      - containerPort: 7522
        name: gateways
        protocol: TCP
      - containerPort: 8222
        name: monitor
        protocol: TCP
      - containerPort: 7777
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8222
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/nats-config
        name: config-volume
      - mountPath: /var/run/nats
        name: pid
      - mountPath: /etc/nats-config/accounts
        name: resolver-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8htjt
        readOnly: true
    - command:
      - nats-server-config-reloader
      - -pid
      - /var/run/nats/nats.pid
      - -config
      - /etc/nats-config/nats.conf
      image: connecteverything/nats-server-config-reloader:0.6.0
      imagePullPolicy: IfNotPresent
      name: reloader
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/nats-config
        name: config-volume
      - mountPath: /var/run/nats
        name: pid
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8htjt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: meshery-broker-0
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: meshery-operator
    serviceAccountName: meshery-operator
    shareProcessNamespace: true
    subdomain: meshery-nats
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: meshery-nats-config
      name: config-volume
    - emptyDir: {}
      name: pid
    - configMap:
        defaultMode: 420
        name: meshery-nats-accounts
      name: resolver-volume
    - name: kube-api-access-8htjt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:52Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:48:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:48:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://068a8d18158e2f912d8c8e7dc0412c33e089e0183c7588951a8557bd2bf9053c
      image: docker.io/library/nats:2.8.2-alpine3.15
      imageID: docker.io/library/nats@sha256:51ed1dcadcd928cbca6b4b2846491bd14667dca111ac63fdb001eef89cb9192f
      lastState: {}
      name: nats
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:51Z"
    - containerID: containerd://cf7c61c6df96dce206d520addbd7a523b63aaaac0640b0102dcb14a006628711
      image: docker.io/connecteverything/nats-server-config-reloader:0.6.0
      imageID: docker.io/connecteverything/nats-server-config-reloader@sha256:c5e1af9a7667ce15f036a8bb0984bb59472e5340faeb3cc314538885de21da9f
      lastState: {}
      name: reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:51Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.22
    podIPs:
    - ip: 192.168.0.22
    qosClass: BestEffort
    startTime: "2025-01-09T22:47:50Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      meshery/component-type: management-plane
    creationTimestamp: "2025-01-09T22:47:50Z"
    generateName: meshery-meshsync-59747c798d-
    labels:
      app: meshery
      component: meshsync
      pod-template-hash: 59747c798d
    name: meshery-meshsync-59747c798d-9r49n
    namespace: meshery
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: meshery-meshsync-59747c798d
      uid: 91d30ddd-dfa8-4eac-83b2-18fa5124a4d7
    resourceVersion: "62656783"
    uid: 21f9c913-e30b-45a0-9b6a-331816e8d73f
  spec:
    containers:
    - command:
      - ./meshery-meshsync
      - --broker-url
      - $(BROKER_URL)
      env:
      - name: BROKER_URL
        value: 10.109.58.0:4222
      image: layer5/meshsync:stable-latest
      imagePullPolicy: Always
      name: meshsync
      ports:
      - containerPort: 11000
        hostPort: 11000
        name: client
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rd5pv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: meshery-operator
    serviceAccountName: meshery-operator
    shareProcessNamespace: true
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rd5pv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:53Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6911f3ea2efb16d508decb7cbf5bac886a00b1dac4acbc5ce749ae182d1b4698
      image: docker.io/layer5/meshsync:stable-latest
      imageID: docker.io/layer5/meshsync@sha256:b3c6942fcb8d0e22295258e1274147b892857506302dd6c8569e80e919e515eb
      lastState: {}
      name: meshsync
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:52Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.23
    podIPs:
    - ip: 192.168.0.23
    qosClass: BestEffort
    startTime: "2025-01-09T22:47:50Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-01-09T22:47:28Z"
    generateName: meshery-operator-7c77d9b57f-
    labels:
      app.kubernetes.io/instance: meshery-operator
      app.kubernetes.io/name: meshery-operator
      pod-template-hash: 7c77d9b57f
    name: meshery-operator-7c77d9b57f-xb8hj
    namespace: meshery
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: meshery-operator-7c77d9b57f
      uid: 227583ff-454b-4fc2-806e-f02b35fb705c
    resourceVersion: "62656720"
    uid: 5bc8c345-f6c5-49f6-92f2-610edfd199d9
  spec:
    containers:
    - args:
      - --metrics-addr=127.0.0.1:8080
      - --enable-leader-election
      command:
      - /manager
      image: layer5/meshery-operator:stable-latest
      imagePullPolicy: Always
      name: manager
      ports:
      - containerPort: 9443
        name: server
        protocol: TCP
      - containerPort: 8080
        name: metrics
        protocol: TCP
      resources: {}
      securityContext: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vpttp
        readOnly: true
    - args:
      - --secure-listen-address=0.0.0.0:8443
      - --upstream=http://127.0.0.1:8080/
      - --logtostderr=false
      - --v=10
      image: gcr.io/kubebuilder/kube-rbac-proxy:v0.16.0
      imagePullPolicy: Always
      name: kube-rbac-proxy
      ports:
      - containerPort: 8443
        name: https
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vpttp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: meshery-operator
    serviceAccountName: meshery-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-vpttp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:28Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-09T22:47:28Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7dd74cb043d23e96335389c1736b9dfb9773987abc4f1a9c49a7df6df655c30b
      image: gcr.io/kubebuilder/kube-rbac-proxy:v0.16.0
      imageID: gcr.io/kubebuilder/kube-rbac-proxy@sha256:771a9a173e033a3ad8b46f5c00a7036eaa88c8d8d1fbd89217325168998113ea
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:49Z"
    - containerID: containerd://746223ded1e0dc3cbfe2e29ad866458d1579e3cc8d29e32b0d0aefbbb656e481
      image: docker.io/layer5/meshery-operator:stable-latest
      imageID: docker.io/layer5/meshery-operator@sha256:a23e9192b47012afd66d3341436efdf0bbe878ea5e7db2968f8e93b8d75dfd98
      lastState: {}
      name: manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-09T22:47:48Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.21
    podIPs:
    - ip: 192.168.0.21
    qosClass: BestEffort
    startTime: "2025-01-09T22:47:28Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T04:00:06Z"
    generateName: metallb-controller-c65987fdb-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: metallb
      app.kubernetes.io/name: metallb
      pod-template-hash: c65987fdb
    name: metallb-controller-c65987fdb-fqf5r
    namespace: metallb
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metallb-controller-c65987fdb
      uid: 2124dcf4-9632-4321-b99f-660c475eff76
    resourceVersion: "47870702"
    uid: 3793711f-102f-4769-9102-646c8e8ee254
  spec:
    containers:
    - args:
      - --port=7472
      - --log-level=info
      - --tls-min-version=VersionTLS12
      env:
      - name: METALLB_ML_SECRET_NAME
        value: metallb-memberlist
      - name: METALLB_DEPLOYMENT
        value: metallb-controller
      - name: METALLB_BGP_TYPE
        value: frr
      image: quay.io/metallb/controller:v0.14.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 7472
        name: monitoring
        protocol: TCP
      - containerPort: 9443
        name: webhook-server
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/k8s-webhook-server/serving-certs
        name: cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cjxs8
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: metallb-controller
    serviceAccountName: metallb-controller
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: cert
      secret:
        defaultMode: 420
        secretName: metallb-webhook-cert
    - name: kube-api-access-cjxs8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:07Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:50:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7e1ea21d9e1066fcb05f49cdf8a4fe1eabedc26e87ac87a208182ad77c5ea193
      image: quay.io/metallb/controller:v0.14.4
      imageID: quay.io/metallb/controller@sha256:bbef1ee3e7d34e344b318266a18e50cba94aa08c59610fb9a5450a9947c4ade1
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:00:07Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.5
    podIPs:
    - ip: 192.168.0.5
    qosClass: BestEffort
    startTime: "2024-04-01T04:00:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-04-01T04:00:06Z"
    generateName: metallb-speaker-
    labels:
      app.kubernetes.io/component: speaker
      app.kubernetes.io/instance: metallb
      app.kubernetes.io/name: metallb
      controller-revision-hash: 695ddbf6cd
      pod-template-generation: "1"
    name: metallb-speaker-6znzb
    namespace: metallb
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: metallb-speaker
      uid: 8a96e7a5-a2e3-491d-94f9-4a3b7202fa5a
    resourceVersion: "47870917"
    uid: 5c1a65c6-176e-46c9-a329-98ee86faccaf
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - c3-medium-x86-03-meshery
    containers:
    - args:
      - --port=7472
      - --log-level=info
      env:
      - name: METALLB_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: METALLB_HOST
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      - name: METALLB_ML_BIND_ADDR
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: METALLB_ML_LABELS
        value: app.kubernetes.io/name=metallb,app.kubernetes.io/component=speaker
      - name: METALLB_ML_BIND_PORT
        value: "7946"
      - name: METALLB_ML_SECRET_KEY_PATH
        value: /etc/ml_secret_key
      - name: FRR_CONFIG_FILE
        value: /etc/frr_reloader/frr.conf
      - name: FRR_RELOADER_PID_FILE
        value: /etc/frr_reloader/reloader.pid
      - name: METALLB_BGP_TYPE
        value: frr
      image: quay.io/metallb/speaker:v0.14.4
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: speaker
      ports:
      - containerPort: 7472
        hostPort: 7472
        name: monitoring
        protocol: TCP
      - containerPort: 7946
        hostPort: 7946
        name: memberlist-tcp
        protocol: TCP
      - containerPort: 7946
        hostPort: 7946
        name: memberlist-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /metrics
          port: monitoring
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_RAW
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ml_secret_key
        name: memberlist
      - mountPath: /etc/frr_reloader
        name: reloader
      - mountPath: /etc/metallb
        name: metallb-excludel2
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    - command:
      - /bin/sh
      - -c
      - |
        /sbin/tini -- /usr/lib/frr/docker-start &
        attempts=0
        until [[ -f /etc/frr/frr.log || $attempts -eq 60 ]]; do
          sleep 1
          attempts=$(( $attempts + 1 ))
        done
        tail -f /etc/frr/frr.log
      env:
      - name: TINI_SUBREAPER
        value: "true"
      image: quay.io/frrouting/frr:9.0.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: livez
          port: 7473
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: frr
      resources: {}
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
          - SYS_ADMIN
          - NET_BIND_SERVICE
      startupProbe:
        failureThreshold: 30
        httpGet:
          path: /livez
          port: 7473
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/frr
        name: frr-sockets
      - mountPath: /etc/frr
        name: frr-conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    - command:
      - /etc/frr_reloader/frr-reloader.sh
      image: quay.io/frrouting/frr:9.0.2
      imagePullPolicy: IfNotPresent
      name: reloader
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/frr
        name: frr-sockets
      - mountPath: /etc/frr
        name: frr-conf
      - mountPath: /etc/frr_reloader
        name: reloader
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    - args:
      - --metrics-port=7473
      command:
      - /etc/frr_metrics/frr-metrics
      image: quay.io/frrouting/frr:9.0.2
      imagePullPolicy: IfNotPresent
      name: frr-metrics
      ports:
      - containerPort: 7473
        hostPort: 7473
        name: monitoring
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/frr
        name: frr-sockets
      - mountPath: /etc/frr
        name: frr-conf
      - mountPath: /etc/frr_metrics
        name: metrics
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - command:
      - /bin/sh
      - -c
      - cp -rLf /tmp/frr/* /etc/frr/
      image: quay.io/frrouting/frr:9.0.2
      imagePullPolicy: IfNotPresent
      name: cp-frr-files
      resources: {}
      securityContext:
        runAsGroup: 101
        runAsUser: 100
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/frr
        name: frr-startup
      - mountPath: /etc/frr
        name: frr-conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    - command:
      - /bin/sh
      - -c
      - cp -f /frr-reloader.sh /etc/frr_reloader/
      image: quay.io/metallb/speaker:v0.14.4
      imagePullPolicy: IfNotPresent
      name: cp-reloader
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/frr_reloader
        name: reloader
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    - command:
      - /bin/sh
      - -c
      - cp -f /frr-metrics /etc/frr_metrics/
      image: quay.io/metallb/speaker:v0.14.4
      imagePullPolicy: IfNotPresent
      name: cp-metrics
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/frr_metrics
        name: metrics
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-npjfz
        readOnly: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metallb-speaker
    serviceAccountName: metallb-speaker
    shareProcessNamespace: true
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: memberlist
      secret:
        defaultMode: 420
        secretName: metallb-memberlist
    - configMap:
        defaultMode: 256
        name: metallb-excludel2
      name: metallb-excludel2
    - emptyDir: {}
      name: frr-sockets
    - configMap:
        defaultMode: 420
        name: metallb-frr-startup
      name: frr-startup
    - emptyDir: {}
      name: frr-conf
    - emptyDir: {}
      name: reloader
    - emptyDir: {}
      name: metrics
    - name: kube-api-access-npjfz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:02Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-06T05:51:02Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-04-01T04:00:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://70d05d4541097f163c549a6ee7b64a7b95739b7a49c7a29026c260b1e4d6c732
      image: quay.io/frrouting/frr:9.0.2
      imageID: quay.io/frrouting/frr@sha256:086acb1278fe86118345f456a1fbfafb80c34d03f7bca9137da0729a1aee5e9c
      lastState: {}
      name: frr
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:00:10Z"
    - containerID: containerd://171924efd0672ed82f7a5d077c5515f05e052a69ae6c9c6414a3f5fdaf1c1c59
      image: quay.io/frrouting/frr:9.0.2
      imageID: quay.io/frrouting/frr@sha256:086acb1278fe86118345f456a1fbfafb80c34d03f7bca9137da0729a1aee5e9c
      lastState: {}
      name: frr-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:00:10Z"
    - containerID: containerd://36d14384bf61ac6e9e75a8b75a0579a7d603373bedccffcb994936d72b7812b6
      image: quay.io/frrouting/frr:9.0.2
      imageID: quay.io/frrouting/frr@sha256:086acb1278fe86118345f456a1fbfafb80c34d03f7bca9137da0729a1aee5e9c
      lastState: {}
      name: reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:00:10Z"
    - containerID: containerd://a75efee584682034e1059fd66314135488c1a9be21671e209638aa89219f5d7d
      image: quay.io/metallb/speaker:v0.14.4
      imageID: quay.io/metallb/speaker@sha256:37611bde45a206195df4866e58824929c407f7971ffbbbebbd5ab6e4f0f20234
      lastState: {}
      name: speaker
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-04-01T04:00:10Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://e392c3492ffc8a6a7b417ad10f4ae362ff6fca76be5560f9ba165a2d028d3ebb
      image: quay.io/frrouting/frr:9.0.2
      imageID: quay.io/frrouting/frr@sha256:086acb1278fe86118345f456a1fbfafb80c34d03f7bca9137da0729a1aee5e9c
      lastState: {}
      name: cp-frr-files
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://e392c3492ffc8a6a7b417ad10f4ae362ff6fca76be5560f9ba165a2d028d3ebb
          exitCode: 0
          finishedAt: "2024-04-01T04:00:07Z"
          reason: Completed
          startedAt: "2024-04-01T04:00:07Z"
    - containerID: containerd://c5a7e370c443b8ebf488b609c9301c15139c4583fb8088f4a0c93768fe596739
      image: quay.io/metallb/speaker:v0.14.4
      imageID: quay.io/metallb/speaker@sha256:37611bde45a206195df4866e58824929c407f7971ffbbbebbd5ab6e4f0f20234
      lastState: {}
      name: cp-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c5a7e370c443b8ebf488b609c9301c15139c4583fb8088f4a0c93768fe596739
          exitCode: 0
          finishedAt: "2024-04-01T04:00:08Z"
          reason: Completed
          startedAt: "2024-04-01T04:00:08Z"
    - containerID: containerd://34127b09f3ff01b89a0f79fa41749d4f1b43e2ff2d729e6863e9ed96db869cc0
      image: quay.io/metallb/speaker:v0.14.4
      imageID: quay.io/metallb/speaker@sha256:37611bde45a206195df4866e58824929c407f7971ffbbbebbd5ab6e4f0f20234
      lastState: {}
      name: cp-metrics
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://34127b09f3ff01b89a0f79fa41749d4f1b43e2ff2d729e6863e9ed96db869cc0
          exitCode: 0
          finishedAt: "2024-04-01T04:00:09Z"
          reason: Completed
          startedAt: "2024-04-01T04:00:09Z"
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: BestEffort
    startTime: "2024-04-01T04:00:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/hydra-config: c52870726676f7ba3aa19fdf34f8fa1f8f266ed0b1750aa23d5aa00c10e68bf3
      checksum/hydra-secrets: e3d519a3a711383641afd27a94d503b8a4683060923bfda6faa97d805718ed36
    creationTimestamp: "2024-11-26T08:56:06Z"
    generateName: layer5-hydra-7854b8559d-
    labels:
      app.kubernetes.io/instance: layer5
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: hydra
      app.kubernetes.io/version: v1.11.8
      helm.sh/chart: hydra-0.24.2
      pod-template-hash: 7854b8559d
    name: layer5-hydra-7854b8559d-m654g
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: layer5-hydra-7854b8559d
      uid: e70be5ec-fc63-4d45-8899-e14289ad89b7
    resourceVersion: "53125602"
    uid: 67b3004d-222f-45e7-b339-f275069c8886
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - serve
      - all
      - --dangerous-force-http
      - --config
      - /etc/config/hydra.yaml
      command:
      - hydra
      env:
      - name: URLS_SELF_ISSUER
        value: https://cloud.layer5.io/hydra
      - name: DSN
        valueFrom:
          secretKeyRef:
            key: dsn
            name: layer5-hydra
      - name: SECRETS_SYSTEM
        valueFrom:
          secretKeyRef:
            key: secretsSystem
            name: layer5-hydra
      - name: SECRETS_COOKIE
        valueFrom:
          secretKeyRef:
            key: secretsCookie
            name: layer5-hydra
      image: oryd/hydra:v1.11.8
      imagePullPolicy: IfNotPresent
      lifecycle: {}
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health/alive
          port: http-admin
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: hydra
      ports:
      - containerPort: 4444
        name: http-public
        protocol: TCP
      - containerPort: 4445
        name: http-admin
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          path: /health/ready
          port: http-admin
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 100
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: hydra-config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8rvhh
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: layer5-hydra
    serviceAccountName: layer5-hydra
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: layer5-hydra
      name: hydra-config-volume
    - name: kube-api-access-8rvhh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://32249034b6041a5a45a53c6e7b5d9e2d0729fd79c53c96301c270218ac1d8aa7
      image: docker.io/oryd/hydra:v1.11.8
      imageID: docker.io/oryd/hydra@sha256:6314bcd5b7f536773cbc0033a325c3a980cabe23f21cc47148e23bbe9a824341
      lastState: {}
      name: hydra
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-26T08:56:07Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.19
    podIPs:
    - ip: 192.168.0.19
    qosClass: BestEffort
    startTime: "2024-11-26T08:56:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-26T08:56:06Z"
    generateName: layer5-hydra-maester-5c558b9b7b-
    labels:
      app.kubernetes.io/instance: layer5
      app.kubernetes.io/name: layer5-hydra-maester
      control-plane: controller-manager
      pod-template-hash: 5c558b9b7b
    name: layer5-hydra-maester-5c558b9b7b-8x6gw
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: layer5-hydra-maester-5c558b9b7b
      uid: e157530d-a1bb-49e9-bf63-35b12f7dfd95
    resourceVersion: "53125521"
    uid: 35cfa1e3-2792-4947-ad88-be09250f81ba
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --metrics-addr=127.0.0.1:8080
      - --hydra-url=http://layer5-hydra-admin
      - --hydra-port=4445
      command:
      - /manager
      image: oryd/hydra-maester:v0.0.25
      imagePullPolicy: IfNotPresent
      name: hydra-maester
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q9qsz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: layer5-hydra-maester-account
    serviceAccountName: layer5-hydra-maester-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-q9qsz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-26T08:56:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9917a61c010861fc2cc390bc21bc51384570f6ff7bd4f7d9aa28cde9a02cea2c
      image: docker.io/oryd/hydra-maester:v0.0.25
      imageID: docker.io/oryd/hydra-maester@sha256:33dd0103b25b4a5fbd169245ed89686b51ce9abb07ce868083ddf808f8dabf86
      lastState: {}
      name: hydra-maester
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-26T08:56:07Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.17
    podIPs:
    - ip: 192.168.0.17
    qosClass: BestEffort
    startTime: "2024-11-26T08:56:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/kratos-config: cb52a43523bc090ee27026eac852b8ec94894047102722d74af5a2706eceec68
      checksum/kratos-secrets: 886b4147f80b76b2349a8fb442dc47bba4cf14e85489948b15abbddd6337618e
      checksum/kratos-templates: 06dc42590b5035ee28993ffdf0195d39cca757fd9ebb428f06d4935bf3c03af6
    creationTimestamp: "2025-02-05T20:44:22Z"
    generateName: layer5-kratos-67cc7867bc-
    labels:
      app.kubernetes.io/instance: layer5
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kratos
      app.kubernetes.io/version: v1.0.0
      helm.sh/chart: kratos-0.39.1
      pod-template-hash: 67cc7867bc
    name: layer5-kratos-67cc7867bc-hrghj
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: layer5-kratos-67cc7867bc
      uid: 726ec2d1-8bd7-4501-ae9f-330c263386b2
    resourceVersion: "68660742"
    uid: e0fb7040-c092-4cfe-ac44-239e8f7e4ac7
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - serve
      - all
      - --config
      - /etc/config/kratos.yaml
      command:
      - kratos
      env:
      - name: DSN
        valueFrom:
          secretKeyRef:
            key: dsn
            name: layer5-kratos
      - name: SECRETS_DEFAULT
        valueFrom:
          secretKeyRef:
            key: secretsDefault
            name: layer5-kratos
            optional: true
      - name: SECRETS_COOKIE
        valueFrom:
          secretKeyRef:
            key: secretsCookie
            name: layer5-kratos
            optional: true
      - name: SECRETS_CIPHER
        valueFrom:
          secretKeyRef:
            key: secretsCipher
            name: layer5-kratos
            optional: true
      - name: COURIER_SMTP_CONNECTION_URI
        valueFrom:
          secretKeyRef:
            key: smtpConnectionURI
            name: layer5-kratos
      image: oryd/kratos:v1.0.0
      imagePullPolicy: IfNotPresent
      lifecycle: {}
      livenessProbe:
        failureThreshold: 5
        httpGet:
          httpHeaders:
          - name: Host
            value: 127.0.0.1
          path: /admin/health/alive
          port: 4434
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: kratos
      ports:
      - containerPort: 4434
        name: http-admin
        protocol: TCP
      - containerPort: 4433
        name: http-public
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          httpHeaders:
          - name: Host
            value: 127.0.0.1
          path: /admin/health/ready
          port: 4434
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seLinuxOptions:
          level: s0:c123,c456
        seccompProfile:
          type: RuntimeDefault
      startupProbe:
        failureThreshold: 60
        httpGet:
          httpHeaders:
          - name: Host
            value: 127.0.0.1
          path: /admin/health/ready
          port: 4434
          scheme: HTTP
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 1
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: kratos-config-volume
        readOnly: true
      - mountPath: /conf/courier-templates/recovery/valid
        name: kratos-template-recovery-valid-volume
        readOnly: true
      - mountPath: /conf/courier-templates/verification/valid
        name: kratos-template-verification-valid-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-nnnvr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      fsGroupChangePolicy: OnRootMismatch
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: layer5-kratos
    serviceAccountName: layer5-kratos
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: layer5-kratos-config
      name: kratos-config-volume
    - configMap:
        defaultMode: 420
        name: layer5-kratos-template-recovery-valid
      name: kratos-template-recovery-valid-volume
    - configMap:
        defaultMode: 420
        name: layer5-kratos-template-verification-valid
      name: kratos-template-verification-valid-volume
    - name: kube-api-access-nnnvr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://35c551e6070fd1fc13f757d6c93af7c51905e6c41f68b44661da5ee027863df1
      image: docker.io/oryd/kratos:v1.0.0
      imageID: docker.io/oryd/kratos@sha256:d06fc5845f632ef03461a92df00986ade16e211848d96d646cbe96df5831e015
      lastState: {}
      name: kratos
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-02-05T20:44:22Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.30
    podIPs:
    - ip: 192.168.0.30
    qosClass: BestEffort
    startTime: "2025-02-05T20:44:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/kratos-config: cb52a43523bc090ee27026eac852b8ec94894047102722d74af5a2706eceec68
      checksum/kratos-secrets: f3ef82ab544cab2f066a6efe684566ed2ee5a06133a365d339de9d4af8073aa0
      checksum/kratos-templates: 06dc42590b5035ee28993ffdf0195d39cca757fd9ebb428f06d4935bf3c03af6
    creationTimestamp: "2025-02-05T20:44:22Z"
    generateName: layer5-kratos-courier-
    labels:
      app.kubernetes.io/instance: layer5
      app.kubernetes.io/name: layer5-kratos-courier
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: layer5-kratos-courier-86789f986f
      statefulset.kubernetes.io/pod-name: layer5-kratos-courier-0
    name: layer5-kratos-courier-0
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: layer5-kratos-courier
      uid: 4d7d6dad-6662-4465-8ca1-3cd5d38cbd4d
    resourceVersion: "68660715"
    uid: b5fd27ad-d25f-4b40-94bd-2ceb58412f02
  spec:
    containers:
    - args:
      - courier
      - watch
      - --config
      - /etc/config/kratos.yaml
      env:
      - name: LOG_FORMAT
        value: json
      - name: LOG_LEVEL
        value: trace
      - name: DSN
        valueFrom:
          secretKeyRef:
            key: dsn
            name: layer5-kratos
      - name: SECRETS_DEFAULT
        valueFrom:
          secretKeyRef:
            key: secretsDefault
            name: layer5-kratos
            optional: true
      - name: SECRETS_COOKIE
        valueFrom:
          secretKeyRef:
            key: secretsCookie
            name: layer5-kratos
            optional: true
      - name: SECRETS_CIPHER
        valueFrom:
          secretKeyRef:
            key: secretsCipher
            name: layer5-kratos
            optional: true
      - name: COURIER_SMTP_CONNECTION_URI
        valueFrom:
          secretKeyRef:
            key: smtpConnectionURI
            name: layer5-kratos
      image: oryd/kratos:v1.0.0
      imagePullPolicy: IfNotPresent
      name: layer5-kratos-courier
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seLinuxOptions:
          level: s0:c123,c456
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: layer5-kratos-config-volume
        readOnly: true
      - mountPath: /conf/courier-templates/recovery/valid
        name: kratos-template-recovery-valid-volume
        readOnly: true
      - mountPath: /conf/courier-templates/verification/valid
        name: kratos-template-verification-valid-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xjvlb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: layer5-kratos-courier-0
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      fsGroupChangePolicy: OnRootMismatch
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: layer5-kratos
    serviceAccountName: layer5-kratos
    subdomain: layer5-kratos-courier
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: layer5-kratos-config
      name: layer5-kratos-config-volume
    - configMap:
        defaultMode: 420
        name: layer5-kratos-template-recovery-valid
      name: kratos-template-recovery-valid-volume
    - configMap:
        defaultMode: 420
        name: layer5-kratos-template-verification-valid
      name: kratos-template-verification-valid-volume
    - name: kube-api-access-xjvlb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:23Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:23Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:23Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f3e2afbf61c9fde0b15cd574d5477bd3ca58680509ba33d72231eb79f26e6d0f
      image: docker.io/oryd/kratos:v1.0.0
      imageID: docker.io/oryd/kratos@sha256:d06fc5845f632ef03461a92df00986ade16e211848d96d646cbe96df5831e015
      lastState: {}
      name: layer5-kratos-courier
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-02-05T20:44:23Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.34
    podIPs:
    - ip: 192.168.0.34
    qosClass: BestEffort
    startTime: "2025-02-05T20:44:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-02-05T20:44:22Z"
    generateName: meshery-cloud-ff748db68-
    labels:
      app.kubernetes.io/instance: layer5
      app.kubernetes.io/name: layer5-cloud
      pod-template-hash: ff748db68
    name: meshery-cloud-ff748db68-7shht
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: meshery-cloud-ff748db68
      uid: 69ef2c25-64d4-4e4e-a476-e148d94db769
    resourceVersion: "69250949"
    uid: d9f69b8b-8bd9-41c2-a9b7-e48b9a9e2502
  spec:
    containers:
    - envFrom:
      - configMapRef:
          name: meshery-cloud-cm
      - secretRef:
          name: meshery-cloud-secret
      image: layer5/meshery-cloud:production-v0.8.145
      imagePullPolicy: IfNotPresent
      name: layer5-cloud
      ports:
      - containerPort: 9876
        name: http
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-b4t5k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: github-app-key
      secret:
        defaultMode: 420
        secretName: meshery-cloud
    - name: kube-api-access-b4t5k
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-08T12:19:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-08T12:19:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-02-05T20:44:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://02624db9002611d159989068514b5d2c77f5ec5717bece493e8fb8269578b956
      image: docker.io/layer5/meshery-cloud:production-v0.8.145
      imageID: docker.io/layer5/meshery-cloud@sha256:4d191a1bd8c53110aae9d7869210727688750153a297408d9e44dbc1f3508548
      lastState:
        terminated:
          containerID: containerd://bc580fba641cf51891024e61909e8dd3caa5259e92d0e17f005fe0363a808778
          exitCode: 2
          finishedAt: "2025-02-08T12:19:14Z"
          reason: Error
          startedAt: "2025-02-08T00:23:59Z"
      name: layer5-cloud
      ready: true
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2025-02-08T12:19:14Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.24
    podIPs:
    - ip: 192.168.0.24
    qosClass: BestEffort
    startTime: "2025-02-05T20:44:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/extended-configuration: 34199d0d7cc8de5820d3d988558376cd7170e73b7afaacdb0cb2e6249be37bf2
    creationTimestamp: "2024-12-06T15:05:37Z"
    generateName: postgresql-primary-
    labels:
      app.kubernetes.io/component: primary
      app.kubernetes.io/instance: postgresql
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/version: 16.1.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: postgresql-primary-b78474b8b
      helm.sh/chart: postgresql-14.0.1
      statefulset.kubernetes.io/pod-name: postgresql-primary-0
    name: postgresql-primary-0
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: postgresql-primary
      uid: f4b92ce2-2787-431d-ae33-7f0e0a0d85c1
    resourceVersion: "68535645"
    uid: a61e8e2a-2bc7-4913-b322-3f033b7d1321
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: primary
                app.kubernetes.io/instance: postgresql
                app.kubernetes.io/name: postgresql
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "true"
      - name: POSTGRESQL_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_VOLUME_DIR
        value: /bitnami/postgresql
      - name: PGDATA
        value: /bitnami/postgresql/data
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: postgresql
      - name: POSTGRES_DATABASE
        value: postgres
      - name: POSTGRES_REPLICATION_MODE
        value: master
      - name: POSTGRES_REPLICATION_USER
        value: repl_user
      - name: POSTGRES_REPLICATION_PASSWORD
        valueFrom:
          secretKeyRef:
            key: replication-password
            name: postgresql
      - name: POSTGRES_CLUSTER_APP_NAME
        value: my_application
      - name: POSTGRES_INITSCRIPTS_USERNAME
        value: postgres
      - name: POSTGRES_INITSCRIPTS_PASSWORD
        value: postgres
      - name: POSTGRESQL_ENABLE_LDAP
        value: "no"
      - name: POSTGRESQL_ENABLE_TLS
        value: "no"
      - name: POSTGRESQL_LOG_HOSTNAME
        value: "false"
      - name: POSTGRESQL_LOG_CONNECTIONS
        value: "false"
      - name: POSTGRESQL_LOG_DISCONNECTIONS
        value: "false"
      - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
        value: "off"
      - name: POSTGRESQL_CLIENT_MIN_MESSAGES
        value: error
      - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
        value: pgaudit, pg_cron
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: postgresql
      ports:
      - containerPort: 5432
        name: tcp-postgresql
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - -e
          - |
            exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /docker-entrypoint-initdb.d/
        name: custom-init-scripts
      - mountPath: /bitnami/postgresql/conf/conf.d/
        name: postgresql-extended-config
      - mountPath: /dev/shm
        name: dshm
      - mountPath: /bitnami/postgresql
        name: data
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: postgresql-primary-0
    initContainers:
    - command:
      - /bin/sh
      - -ec
      - |
        chown 1001:1001 /bitnami/postgresql
        mkdir -p /bitnami/postgresql/data
        chmod 700 /bitnami/postgresql/data
        find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name "conf" -not -name ".snapshot" -not -name "lost+found" | \
          xargs -r chown -R 1001:1001
        chmod -R 777 /dev/shm
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imagePullPolicy: IfNotPresent
      name: init-chmod-data
      resources: {}
      securityContext:
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/postgresql
        name: data
      - mountPath: /dev/shm
        name: dshm
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: postgresql
    serviceAccountName: postgresql
    subdomain: postgresql-primary-hl
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-postgresql-primary-0
    - configMap:
        defaultMode: 420
        name: postgresql-primary-extended-configuration
      name: postgresql-extended-config
    - configMap:
        defaultMode: 420
        name: postgresql-primary-init-scripts
      name: custom-init-scripts
    - emptyDir:
        medium: Memory
      name: dshm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://137c78fad40a1dc366c62e24e5a236e8c3bb09670981b0a919a0f430540d63d9
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imageID: docker.io/layer5/postgres-ext@sha256:9c343b1a05ff79af483d4ebb2e60ed6b9c8d65afdb50bee38c5158d5723e7ff6
      lastState: {}
      name: postgresql
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-06T15:05:39Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://90c8e8c1420c85494f0520ec32fe4ac64501e00bec18edb056c75cf22c28b4fe
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imageID: docker.io/bitnami/os-shell@sha256:8643af4facffb20e14d135b9e5bdae7f4e604db1e755896f60ea55d05ca09287
      lastState: {}
      name: init-chmod-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://90c8e8c1420c85494f0520ec32fe4ac64501e00bec18edb056c75cf22c28b4fe
          exitCode: 0
          finishedAt: "2024-12-06T15:05:38Z"
          reason: Completed
          startedAt: "2024-12-06T15:05:38Z"
    phase: Running
    podIP: 192.168.0.10
    podIPs:
    - ip: 192.168.0.10
    qosClass: Burstable
    startTime: "2024-12-06T15:05:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-12-06T15:05:37Z"
    generateName: postgresql-read-
    labels:
      app.kubernetes.io/component: read
      app.kubernetes.io/instance: postgresql
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/version: 16.1.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: postgresql-read-744ffbf4c8
      helm.sh/chart: postgresql-14.0.1
      statefulset.kubernetes.io/pod-name: postgresql-read-0
    name: postgresql-read-0
    namespace: prod-cloud
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: postgresql-read
      uid: 3b02cea0-3f88-4f39-989f-df10a4f59666
    resourceVersion: "55882232"
    uid: d6fe01e6-89b2-4906-be37-a175b3cc67d7
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: read
                app.kubernetes.io/instance: postgresql
                app.kubernetes.io/name: postgresql
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "true"
      - name: POSTGRESQL_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_VOLUME_DIR
        value: /bitnami/postgresql
      - name: PGDATA
        value: /bitnami/postgresql/data
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: postgresql
      - name: POSTGRES_REPLICATION_MODE
        value: slave
      - name: POSTGRES_REPLICATION_USER
        value: repl_user
      - name: POSTGRES_REPLICATION_PASSWORD
        valueFrom:
          secretKeyRef:
            key: replication-password
            name: postgresql
      - name: POSTGRES_CLUSTER_APP_NAME
        value: my_application
      - name: POSTGRES_MASTER_HOST
        value: postgresql-primary
      - name: POSTGRES_MASTER_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_ENABLE_TLS
        value: "no"
      - name: POSTGRESQL_LOG_HOSTNAME
        value: "false"
      - name: POSTGRESQL_LOG_CONNECTIONS
        value: "false"
      - name: POSTGRESQL_LOG_DISCONNECTIONS
        value: "false"
      - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
        value: "off"
      - name: POSTGRESQL_CLIENT_MIN_MESSAGES
        value: error
      - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
        value: pgaudit, pg_cron
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: postgresql
      ports:
      - containerPort: 5432
        name: tcp-postgresql
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - -e
          - |
            exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev/shm
        name: dshm
      - mountPath: /bitnami/postgresql
        name: data
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: postgresql-read-0
    initContainers:
    - command:
      - /bin/sh
      - -ec
      - |
        chown 1001:1001 /bitnami/postgresql
        mkdir -p /bitnami/postgresql/data
        chmod 700 /bitnami/postgresql/data
        find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name "conf" -not -name ".snapshot" -not -name "lost+found" | \
          xargs -r chown -R 1001:1001
        chmod -R 777 /dev/shm
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imagePullPolicy: IfNotPresent
      name: init-chmod-data
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/postgresql
        name: data
      - mountPath: /dev/shm
        name: dshm
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: postgresql
    serviceAccountName: postgresql
    subdomain: postgresql-read-hl
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-postgresql-read-0
    - emptyDir:
        medium: Memory
      name: dshm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:05:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://02ef509307173d5366a1f9057dd72d8dbd9cbb33958fcb659bb85b5c4f980f42
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imageID: docker.io/layer5/postgres-ext@sha256:9c343b1a05ff79af483d4ebb2e60ed6b9c8d65afdb50bee38c5158d5723e7ff6
      lastState: {}
      name: postgresql
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-06T15:05:38Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://4adaf275719266c61a1347304876129877b38a35f94d906c865dfd47e04ac053
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imageID: docker.io/bitnami/os-shell@sha256:8643af4facffb20e14d135b9e5bdae7f4e604db1e755896f60ea55d05ca09287
      lastState: {}
      name: init-chmod-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://4adaf275719266c61a1347304876129877b38a35f94d906c865dfd47e04ac053
          exitCode: 0
          finishedAt: "2024-12-06T15:05:38Z"
          reason: Completed
          startedAt: "2024-12-06T15:05:38Z"
    phase: Running
    podIP: 192.168.0.8
    podIPs:
    - ip: 192.168.0.8
    qosClass: Burstable
    startTime: "2024-12-06T15:05:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/extended-configuration: f87889db0ef9b135537b114ea9efa54bad8a27cb93848a5c70c95f65bca78ea4
    creationTimestamp: "2024-12-06T15:09:23Z"
    generateName: layer5-db-postgresql-primary-
    labels:
      app.kubernetes.io/component: primary
      app.kubernetes.io/instance: layer5-db
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/version: 16.1.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: layer5-db-postgresql-primary-75974964b
      helm.sh/chart: postgresql-14.0.1
      statefulset.kubernetes.io/pod-name: layer5-db-postgresql-primary-0
    name: layer5-db-postgresql-primary-0
    namespace: prod-db
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: layer5-db-postgresql-primary
      uid: cdb9b4a1-d9ed-4b15-b926-baf49fae57e1
    resourceVersion: "68535666"
    uid: e039c52a-9097-436e-a93b-1984de8a3edd
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: primary
                app.kubernetes.io/instance: layer5-db
                app.kubernetes.io/name: postgresql
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "true"
      - name: POSTGRESQL_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_VOLUME_DIR
        value: /bitnami/postgresql
      - name: PGDATA
        value: /bitnami/postgresql/data
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: layer5-db-postgresql
      - name: POSTGRES_DATABASE
        value: postgres
      - name: POSTGRES_REPLICATION_MODE
        value: master
      - name: POSTGRES_REPLICATION_USER
        value: repl_user
      - name: POSTGRES_REPLICATION_PASSWORD
        valueFrom:
          secretKeyRef:
            key: replication-password
            name: layer5-db-postgresql
      - name: POSTGRES_CLUSTER_APP_NAME
        value: my_application
      - name: POSTGRES_INITSCRIPTS_USERNAME
        value: postgres
      - name: POSTGRES_INITSCRIPTS_PASSWORD
        value: postgres
      - name: POSTGRESQL_ENABLE_LDAP
        value: "no"
      - name: POSTGRESQL_ENABLE_TLS
        value: "no"
      - name: POSTGRESQL_LOG_HOSTNAME
        value: "false"
      - name: POSTGRESQL_LOG_CONNECTIONS
        value: "false"
      - name: POSTGRESQL_LOG_DISCONNECTIONS
        value: "false"
      - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
        value: "off"
      - name: POSTGRESQL_CLIENT_MIN_MESSAGES
        value: error
      - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
        value: pgaudit, pg_cron
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: postgresql
      ports:
      - containerPort: 5432
        name: tcp-postgresql
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - -e
          - |
            exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /docker-entrypoint-initdb.d/
        name: custom-init-scripts
      - mountPath: /bitnami/postgresql/conf/conf.d/
        name: postgresql-extended-config
      - mountPath: /dev/shm
        name: dshm
      - mountPath: /bitnami/postgresql
        name: data
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: layer5-db-postgresql-primary-0
    initContainers:
    - command:
      - /bin/sh
      - -ec
      - |
        chown 1001:1001 /bitnami/postgresql
        mkdir -p /bitnami/postgresql/data
        chmod 700 /bitnami/postgresql/data
        find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name "conf" -not -name ".snapshot" -not -name "lost+found" | \
          xargs -r chown -R 1001:1001
        chmod -R 777 /dev/shm
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imagePullPolicy: IfNotPresent
      name: init-chmod-data
      resources: {}
      securityContext:
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/postgresql
        name: data
      - mountPath: /dev/shm
        name: dshm
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: layer5-db-postgresql
    serviceAccountName: layer5-db-postgresql
    subdomain: layer5-db-postgresql-primary-hl
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-layer5-db-postgresql-primary-0
    - configMap:
        defaultMode: 420
        name: layer5-db-postgresql-primary-extended-configuration
      name: postgresql-extended-config
    - configMap:
        defaultMode: 420
        name: layer5-db-postgresql-primary-init-scripts
      name: custom-init-scripts
    - emptyDir:
        medium: Memory
      name: dshm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:25Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:25Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:23Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3c082cc0e93765c56303118af82a314367eaaf4858255f221884cb5d7bb32f99
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imageID: docker.io/layer5/postgres-ext@sha256:9c343b1a05ff79af483d4ebb2e60ed6b9c8d65afdb50bee38c5158d5723e7ff6
      lastState: {}
      name: postgresql
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-06T15:09:25Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://6cfb32a96bb7831d8b25ba224f2f6a6321432cda3ce48f39bea6c23e518c40a1
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imageID: docker.io/bitnami/os-shell@sha256:8643af4facffb20e14d135b9e5bdae7f4e604db1e755896f60ea55d05ca09287
      lastState: {}
      name: init-chmod-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://6cfb32a96bb7831d8b25ba224f2f6a6321432cda3ce48f39bea6c23e518c40a1
          exitCode: 0
          finishedAt: "2024-12-06T15:09:24Z"
          reason: Completed
          startedAt: "2024-12-06T15:09:24Z"
    phase: Running
    podIP: 192.168.0.11
    podIPs:
    - ip: 192.168.0.11
    qosClass: Burstable
    startTime: "2024-12-06T15:09:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-12-06T15:08:54Z"
    generateName: layer5-db-postgresql-read-
    labels:
      app.kubernetes.io/component: read
      app.kubernetes.io/instance: layer5-db
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/version: 16.1.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: layer5-db-postgresql-read-64c46447b6
      helm.sh/chart: postgresql-14.0.1
      statefulset.kubernetes.io/pod-name: layer5-db-postgresql-read-0
    name: layer5-db-postgresql-read-0
    namespace: prod-db
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: layer5-db-postgresql-read
      uid: de31fe25-0563-47eb-bcfa-4576c25bf790
    resourceVersion: "55083848"
    uid: 7e775f33-8083-474d-9cd1-6be73fa14f93
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: read
                app.kubernetes.io/instance: layer5-db
                app.kubernetes.io/name: postgresql
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: false
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "true"
      - name: POSTGRESQL_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_VOLUME_DIR
        value: /bitnami/postgresql
      - name: PGDATA
        value: /bitnami/postgresql/data
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: layer5-db-postgresql
      - name: POSTGRES_REPLICATION_MODE
        value: slave
      - name: POSTGRES_REPLICATION_USER
        value: repl_user
      - name: POSTGRES_REPLICATION_PASSWORD
        valueFrom:
          secretKeyRef:
            key: replication-password
            name: layer5-db-postgresql
      - name: POSTGRES_CLUSTER_APP_NAME
        value: my_application
      - name: POSTGRES_MASTER_HOST
        value: layer5-db-postgresql-primary
      - name: POSTGRES_MASTER_PORT_NUMBER
        value: "5432"
      - name: POSTGRESQL_ENABLE_TLS
        value: "no"
      - name: POSTGRESQL_LOG_HOSTNAME
        value: "false"
      - name: POSTGRESQL_LOG_CONNECTIONS
        value: "false"
      - name: POSTGRESQL_LOG_DISCONNECTIONS
        value: "false"
      - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
        value: "off"
      - name: POSTGRESQL_CLIENT_MIN_MESSAGES
        value: error
      - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
        value: pgaudit, pg_cron
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imagePullPolicy: Always
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: postgresql
      ports:
      - containerPort: 5432
        name: tcp-postgresql
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - -e
          - |
            exec pg_isready -U "postgres" -d "dbname=postgres" -h 127.0.0.1 -p 5432
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /dev/shm
        name: dshm
      - mountPath: /bitnami/postgresql
        name: data
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: layer5-db-postgresql-read-0
    initContainers:
    - command:
      - /bin/sh
      - -ec
      - |
        chown 1001:1001 /bitnami/postgresql
        mkdir -p /bitnami/postgresql/data
        chmod 700 /bitnami/postgresql/data
        find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name "conf" -not -name ".snapshot" -not -name "lost+found" | \
          xargs -r chown -R 1001:1001
        chmod -R 777 /dev/shm
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imagePullPolicy: IfNotPresent
      name: init-chmod-data
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/postgresql
        name: data
      - mountPath: /dev/shm
        name: dshm
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
    serviceAccount: layer5-db-postgresql
    serviceAccountName: layer5-db-postgresql
    subdomain: layer5-db-postgresql-read-hl
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-layer5-db-postgresql-read-0
    - emptyDir:
        medium: Memory
      name: dshm
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:08:55Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:08:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:09:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-06T15:08:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e24bec337e462ea63d07692ffff827f56e11c348fa94f0df8afe95ba4824e5c3
      image: docker.io/layer5/postgres-ext:12.19-bitnami
      imageID: docker.io/layer5/postgres-ext@sha256:9c343b1a05ff79af483d4ebb2e60ed6b9c8d65afdb50bee38c5158d5723e7ff6
      lastState: {}
      name: postgresql
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-06T15:08:56Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://1c1fdd5df17a8dad99124c6e0221ff7469f861a34ff19d4ce96a45cd25431aab
      image: docker.io/bitnami/os-shell:11-debian-11-r96
      imageID: docker.io/bitnami/os-shell@sha256:8643af4facffb20e14d135b9e5bdae7f4e604db1e755896f60ea55d05ca09287
      lastState: {}
      name: init-chmod-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://1c1fdd5df17a8dad99124c6e0221ff7469f861a34ff19d4ce96a45cd25431aab
          exitCode: 0
          finishedAt: "2024-12-06T15:08:55Z"
          reason: Completed
          startedAt: "2024-12-06T15:08:55Z"
    phase: Running
    podIP: 192.168.0.7
    podIPs:
    - ip: 192.168.0.7
    qosClass: Burstable
    startTime: "2024-12-06T15:08:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: alertmanager
    creationTimestamp: "2024-11-22T07:18:55Z"
    generateName: alertmanager-prometheus-kube-prometheus-alertmanager-
    labels:
      alertmanager: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/instance: prometheus-kube-prometheus-alertmanager
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: 0.27.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: alertmanager-prometheus-kube-prometheus-alertmanager-9d99c5867
      statefulset.kubernetes.io/pod-name: alertmanager-prometheus-kube-prometheus-alertmanager-0
    name: alertmanager-prometheus-kube-prometheus-alertmanager-0
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: alertmanager-prometheus-kube-prometheus-alertmanager
      uid: 8b097e2a-3573-4ec6-8395-eeeb03081c1c
    resourceVersion: "52150613"
    uid: 15cd3d9b-a05e-4a83-8977-5a71239e939a
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - alertmanager
              - key: alertmanager
                operator: In
                values:
                - prometheus-kube-prometheus-alertmanager
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --storage.path=/alertmanager
      - --data.retention=120h
      - --cluster.listen-address=
      - --web.listen-address=:9093
      - --web.external-url=http://prometheus-kube-prometheus-alertmanager.prod-monitoring:9093
      - --web.route-prefix=/
      - --cluster.label=prod-monitoring/prometheus-kube-prometheus-alertmanager
      - --cluster.peer=alertmanager-prometheus-kube-prometheus-alertmanager-0.alertmanager-operated:9094
      - --cluster.reconnect-timeout=5m
      - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/prometheus/alertmanager:v0.27.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 3
      name: alertmanager
      ports:
      - containerPort: 9093
        name: http-web
        protocol: TCP
      - containerPort: 9094
        name: mesh-tcp
        protocol: TCP
      - containerPort: 9094
        name: mesh-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 10
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        initialDelaySeconds: 3
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
      - mountPath: /etc/alertmanager/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/alertmanager/certs
        name: tls-assets
        readOnly: true
      - mountPath: /alertmanager
        name: alertmanager-prometheus-kube-prometheus-alertmanager-db
      - mountPath: /etc/alertmanager/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rf897
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9093/-/reload
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rf897
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: alertmanager-prometheus-kube-prometheus-alertmanager-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
      - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
      - --watched-dir=/etc/alertmanager/config
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "-1"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/alertmanager/config
        name: config-volume
        readOnly: true
      - mountPath: /etc/alertmanager/config_out
        name: config-out
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rf897
        readOnly: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-alertmanager
    serviceAccountName: prometheus-kube-prometheus-alertmanager
    subdomain: alertmanager-operated
    terminationGracePeriodSeconds: 120
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config-volume
      secret:
        defaultMode: 420
        secretName: alertmanager-prometheus-kube-prometheus-alertmanager-generated
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: alertmanager-prometheus-kube-prometheus-alertmanager-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - name: web-config
      secret:
        defaultMode: 420
        secretName: alertmanager-prometheus-kube-prometheus-alertmanager-web-config
    - emptyDir: {}
      name: alertmanager-prometheus-kube-prometheus-alertmanager-db
    - name: kube-api-access-rf897
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:05Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d150904aa7067bdd3e7328055cfd31443b9012ec32b6c3ad006a3f6bc492a816
      image: quay.io/prometheus/alertmanager:v0.27.0
      imageID: quay.io/prometheus/alertmanager@sha256:e13b6ed5cb929eeaee733479dce55e10eb3bc2e9c4586c705a4e8da41e5eacf5
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:19:18Z"
    - containerID: containerd://aff60a041e189758cbe85a6960a9a393db838e5cf2dd72d4b18c0bf75e58d814
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:e2dc5623bcdd39fae332fff7cc3b77cc478f4720b758663e2af59b423b86e878
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:19:18Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://0d7e7bc6cd331839e7249249c5f7290ef454e296f7c95cbe6d7467d8f74647d2
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:e2dc5623bcdd39fae332fff7cc3b77cc478f4720b758663e2af59b423b86e878
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://0d7e7bc6cd331839e7249249c5f7290ef454e296f7c95cbe6d7467d8f74647d2
          exitCode: 0
          finishedAt: "2024-11-22T07:19:04Z"
          reason: Completed
          startedAt: "2024-11-22T07:19:04Z"
    phase: Running
    podIP: 192.168.0.41
    podIPs:
    - ip: 192.168.0.41
    qosClass: Burstable
    startTime: "2024-11-22T07:18:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
      checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
      checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
      kubectl.kubernetes.io/default-container: grafana
    creationTimestamp: "2024-11-22T07:18:43Z"
    generateName: prometheus-grafana-69f9ccfd8d-
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: grafana
      pod-template-hash: 69f9ccfd8d
    name: prometheus-grafana-69f9ccfd8d-5npr6
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-grafana-69f9ccfd8d
      uid: 8fcff22c-c2ab-4b00-a363-87f7b3794d25
    resourceVersion: "52150508"
    uid: ca1921a3-981a-4589-b986-2c48ee05caca
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_dashboard
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /tmp/dashboards
      - name: RESOURCE
        value: both
      - name: NAMESPACE
        value: ALL
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/dashboards/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imagePullPolicy: IfNotPresent
      name: grafana-sc-dashboard
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hblk5
        readOnly: true
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_datasource
      - name: LABEL_VALUE
        value: "1"
      - name: FOLDER
        value: /etc/grafana/provisioning/datasources
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/datasources/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imagePullPolicy: IfNotPresent
      name: grafana-sc-datasources
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hblk5
        readOnly: true
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: prometheus-grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: prometheus-grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:11.3.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
        name: sc-dashboard-provider
        subPath: provider.yaml
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hblk5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: prometheus-grafana
    serviceAccountName: prometheus-grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: prometheus-grafana
      name: config
    - emptyDir: {}
      name: storage
    - emptyDir: {}
      name: sc-dashboard-volume
    - configMap:
        defaultMode: 420
        name: prometheus-grafana-config-dashboards
      name: sc-dashboard-provider
    - emptyDir: {}
      name: sc-datasources-volume
    - name: kube-api-access-hblk5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:01Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:04Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:04Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://238a9591c9694d19b5d674034fea793f6ca7ad8b98f543f6ac2960ea74c45aa1
      image: docker.io/grafana/grafana:11.3.0
      imageID: docker.io/grafana/grafana@sha256:a0f881232a6fb71a0554a47d0fe2203b6888fe77f4cefb7ea62bed7eb54e13c3
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:19:00Z"
    - containerID: containerd://33aeecbde4659097474f7f9e20b6a1f8fb0be8b570a2c653dc4512891580623e
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imageID: quay.io/kiwigrid/k8s-sidecar@sha256:4166a019eeafd1f0fef4d867dc5f224f18d84ec8681dbb31f3ca258ecf07bcf2
      lastState: {}
      name: grafana-sc-dashboard
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:18:53Z"
    - containerID: containerd://3cc2834259449d56811f07bc7e8d2c42972982396cc53cfaa3e8fa57cbd57c37
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imageID: quay.io/kiwigrid/k8s-sidecar@sha256:4166a019eeafd1f0fef4d867dc5f224f18d84ec8681dbb31f3ca258ecf07bcf2
      lastState: {}
      name: grafana-sc-datasources
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:18:53Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.35
    podIPs:
    - ip: 192.168.0.35
    qosClass: BestEffort
    startTime: "2024-11-22T07:18:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-22T07:18:43Z"
    generateName: prometheus-kube-prometheus-operator-6d87886878-
    labels:
      app: kube-prometheus-stack-operator
      app.kubernetes.io/component: prometheus-operator
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
      app.kubernetes.io/part-of: kube-prometheus-stack
      app.kubernetes.io/version: 66.2.1
      chart: kube-prometheus-stack-66.2.1
      heritage: Helm
      pod-template-hash: 6d87886878
      release: prometheus
    name: prometheus-kube-prometheus-operator-6d87886878-8njdj
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-kube-prometheus-operator-6d87886878
      uid: 4326a486-7993-4e84-886d-84a8f91b8655
    resourceVersion: "52150468"
    uid: 0351a862-bce1-45a9-ba89-2b2448414fb6
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --kubelet-service=kube-system/prometheus-kube-prometheus-kubelet
      - --kubelet-endpoints=true
      - --kubelet-endpointslice=false
      - --localhost=127.0.0.1
      - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      - --config-reloader-cpu-request=0
      - --config-reloader-cpu-limit=0
      - --config-reloader-memory-request=0
      - --config-reloader-memory-limit=0
      - --thanos-default-base-image=quay.io/thanos/thanos:v0.36.1
      - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
      - --web.enable-tls=true
      - --web.cert-file=/cert/cert
      - --web.key-file=/cert/key
      - --web.listen-address=:10250
      - --web.tls-min-version=VersionTLS13
      env:
      - name: GOGC
        value: "30"
      image: quay.io/prometheus-operator/prometheus-operator:v0.78.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: kube-prometheus-stack
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /cert
        name: tls-secret
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-stqm2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-operator
    serviceAccountName: prometheus-kube-prometheus-operator
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: tls-secret
      secret:
        defaultMode: 420
        secretName: prometheus-kube-prometheus-admission
    - name: kube-api-access-stqm2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:56Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://a0192a56f3926309cfc42d9f6e24c4cdf9cbb4cc22aba841eb23eb796a1229b6
      image: quay.io/prometheus-operator/prometheus-operator:v0.78.1
      imageID: quay.io/prometheus-operator/prometheus-operator@sha256:29ccb0536e89f03de442fe2e338b9e381d53b9c500f8217bcb45814bcfc01a0a
      lastState: {}
      name: kube-prometheus-stack
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:18:55Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.38
    podIPs:
    - ip: 192.168.0.38
    qosClass: BestEffort
    startTime: "2024-11-22T07:18:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-11-22T07:18:43Z"
    generateName: prometheus-kube-state-metrics-66f5694654-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.14.0
      helm.sh/chart: kube-state-metrics-5.27.0
      pod-template-hash: 66f5694654
      release: prometheus
    name: prometheus-kube-state-metrics-66f5694654-89hv7
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-kube-state-metrics-66f5694654
      uid: fd7469ae-917b-462f-ae4f-20b946ce9814
    resourceVersion: "52150407"
    uid: 0a9729d1-33ff-4f9d-bcbe-2b354618be80
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --port=8080
      - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 8081
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vb8lz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-state-metrics
    serviceAccountName: prometheus-kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-vb8lz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3f1f2ab2e7b0738fc9eb8b30d9a6e68029d54fda34d80a5128b3ed524c8a6799
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0
      imageID: registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:37d841299325c23b56e5951176ce8ef317d537447c0f1b2d2437dddbb1f51165
      lastState: {}
      name: kube-state-metrics
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:18:46Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 192.168.0.31
    podIPs:
    - ip: 192.168.0.31
    qosClass: BestEffort
    startTime: "2024-11-22T07:18:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/default-container: prometheus
    creationTimestamp: "2024-11-22T07:18:55Z"
    generateName: prometheus-prometheus-kube-prometheus-prometheus-
    labels:
      app.kubernetes.io/instance: prometheus-kube-prometheus-prometheus
      app.kubernetes.io/managed-by: prometheus-operator
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/version: 2.55.1
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-prometheus-kube-prometheus-prometheus-65959b9854
      operator.prometheus.io/name: prometheus-kube-prometheus-prometheus
      operator.prometheus.io/shard: "0"
      prometheus: prometheus-kube-prometheus-prometheus
      statefulset.kubernetes.io/pod-name: prometheus-prometheus-kube-prometheus-prometheus-0
    name: prometheus-prometheus-kube-prometheus-prometheus-0
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-prometheus-kube-prometheus-prometheus
      uid: 6930d01d-1e0b-4e58-ab35-0bb8fb202dde
    resourceVersion: "52150620"
    uid: 2ded6686-10ca-4aff-9b7b-8634f9210b94
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - prometheus
              - key: prometheus
                operator: In
                values:
                - prometheus-kube-prometheus-prometheus
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
      - --web.enable-lifecycle
      - --web.external-url=http://prometheus-kube-prometheus-prometheus.prod-monitoring:9090
      - --web.route-prefix=/
      - --storage.tsdb.retention.time=10d
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.wal-compression
      - --web.config.file=/etc/prometheus/web_config/web-config.yaml
      image: quay.io/prometheus/prometheus:v2.55.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 6
        httpGet:
          path: /-/healthy
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      name: prometheus
      ports:
      - containerPort: 9090
        name: http-web
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 3
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /-/ready
          port: http-web
          scheme: HTTP
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 3
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config_out
        name: config-out
        readOnly: true
      - mountPath: /etc/prometheus/certs
        name: tls-assets
        readOnly: true
      - mountPath: /prometheus
        name: prometheus-prometheus-kube-prometheus-prometheus-db
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /etc/prometheus/web_config/web-config.yaml
        name: web-config
        readOnly: true
        subPath: web-config.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cv5sr
        readOnly: true
    - args:
      - --listen-address=:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imagePullPolicy: IfNotPresent
      name: config-reloader
      ports:
      - containerPort: 8080
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cv5sr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-prometheus-kube-prometheus-prometheus-0
    initContainers:
    - args:
      - --watch-interval=0
      - --listen-address=:8081
      - --config-file=/etc/prometheus/config/prometheus.yaml.gz
      - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
      - --watched-dir=/etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      command:
      - /bin/prometheus-config-reloader
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: SHARD
        value: "0"
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imagePullPolicy: IfNotPresent
      name: init-config-reloader
      ports:
      - containerPort: 8081
        name: reloader-web
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/prometheus/config
        name: config
      - mountPath: /etc/prometheus/config_out
        name: config-out
      - mountPath: /etc/prometheus/rules/prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cv5sr
        readOnly: true
    nodeName: c3-medium-x86-03-meshery
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-prometheus-prometheus
    serviceAccountName: prometheus-kube-prometheus-prometheus
    shareProcessNamespace: false
    subdomain: prometheus-operated
    terminationGracePeriodSeconds: 600
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: config
      secret:
        defaultMode: 420
        secretName: prometheus-prometheus-kube-prometheus-prometheus
    - name: tls-assets
      projected:
        defaultMode: 420
        sources:
        - secret:
            name: prometheus-prometheus-kube-prometheus-prometheus-tls-assets-0
    - emptyDir:
        medium: Memory
      name: config-out
    - configMap:
        defaultMode: 420
        name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
      name: prometheus-prometheus-kube-prometheus-prometheus-rulefiles-0
    - name: web-config
      secret:
        defaultMode: 420
        secretName: prometheus-prometheus-kube-prometheus-prometheus-web-config
    - emptyDir: {}
      name: prometheus-prometheus-kube-prometheus-prometheus-db
    - name: kube-api-access-cv5sr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:06Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:19:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://520c75056427a2c8b3cb6542a147e06036536fde95e57bc40cffff314a112cda
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:e2dc5623bcdd39fae332fff7cc3b77cc478f4720b758663e2af59b423b86e878
      lastState: {}
      name: config-reloader
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:19:15Z"
    - containerID: containerd://8b00969c5b01fbdf98e26e2bbd8962d2d42c9269ce73e1aeac1a24d78d580a4c
      image: quay.io/prometheus/prometheus:v2.55.1
      imageID: quay.io/prometheus/prometheus@sha256:2659f4c2ebb718e7695cb9b25ffa7d6be64db013daba13e05c875451cf51b0d3
      lastState: {}
      name: prometheus
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:19:15Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    initContainerStatuses:
    - containerID: containerd://d682211a4b2c5c81d1190acf3df2a2f4e75c1631c2d8a1feed5ad1e4ab2baa80
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.78.1
      imageID: quay.io/prometheus-operator/prometheus-config-reloader@sha256:e2dc5623bcdd39fae332fff7cc3b77cc478f4720b758663e2af59b423b86e878
      lastState: {}
      name: init-config-reloader
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://d682211a4b2c5c81d1190acf3df2a2f4e75c1631c2d8a1feed5ad1e4ab2baa80
          exitCode: 0
          finishedAt: "2024-11-22T07:19:05Z"
          reason: Completed
          startedAt: "2024-11-22T07:19:05Z"
    phase: Running
    podIP: 192.168.0.42
    podIPs:
    - ip: 192.168.0.42
    qosClass: BestEffort
    startTime: "2024-11-22T07:18:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2024-11-22T07:18:43Z"
    generateName: prometheus-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      controller-revision-hash: 6bf7f67466
      helm.sh/chart: prometheus-node-exporter-4.42.0
      jobLabel: node-exporter
      pod-template-generation: "1"
      release: prometheus
    name: prometheus-prometheus-node-exporter-nlln8
    namespace: prod-monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-prometheus-node-exporter
      uid: d85a33c8-0883-4216-9fab-33511603960a
    resourceVersion: "68535705"
    uid: 0f3ad9dc-ca09-486e-b461-206bc3c2de6b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - c3-medium-x86-03-meshery
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.8.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: c3-medium-x86-03-meshery
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-prometheus-node-exporter
    serviceAccountName: prometheus-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:46Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-22T07:18:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://36fbae9bfc96647935f0fd289f203899c9e59c061da5ea7dea56e00c749290f7
      image: quay.io/prometheus/node-exporter:v1.8.2
      imageID: quay.io/prometheus/node-exporter@sha256:4032c6d5bfd752342c3e631c2f1de93ba6b86c41db6b167b9a35372c139e7706
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-11-22T07:18:45Z"
    hostIP: 139.178.83.85
    hostIPs:
    - ip: 139.178.83.85
    phase: Running
    podIP: 139.178.83.85
    podIPs:
    - ip: 139.178.83.85
    qosClass: BestEffort
    startTime: "2024-11-22T07:18:43Z"
kind: List
metadata:
  resourceVersion: ""
