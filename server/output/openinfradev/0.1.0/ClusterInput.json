{"kind":"ClusterInput","apiVersion":"v1alpha2","display-name":"Cluster Input","format":"JSON","metadata":{},"model":{"name":"openinfradev","version":"0.1.0","display-name":"","category":"","sub-category":""},"schema":"{\n \"description\": \"InputSpec defines the desired state of ClusterInput\",\n \"properties\": {\n  \"alias\": {\n   \"description\": \"A user friendly alias name for this input plugin. Used in metrics for distinction of each configured input.\",\n   \"type\": \"string\"\n  },\n  \"customPlugin\": {\n   \"description\": \"CustomPlugin defines Custom Input configuration.\",\n   \"properties\": {\n    \"config\": {\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"dummy\": {\n   \"description\": \"Dummy defines Dummy Input configuration.\",\n   \"properties\": {\n    \"dummy\": {\n     \"description\": \"Dummy JSON record.\",\n     \"type\": \"string\"\n    },\n    \"rate\": {\n     \"description\": \"Events number generated per second.\",\n     \"format\": \"int32\",\n     \"type\": \"integer\"\n    },\n    \"samples\": {\n     \"description\": \"Sample events to generate.\",\n     \"format\": \"int32\",\n     \"type\": \"integer\"\n    },\n    \"tag\": {\n     \"description\": \"Tag name associated to all records comming from this plugin.\",\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"fluentBitMetrics\": {\n   \"description\": \"FluentBitMetrics defines Fluent Bit Metrics Input configuration.\",\n   \"properties\": {\n    \"scrapeInterval\": {\n     \"description\": \"The rate at which metrics are collected from the host operating system. default is 2 seconds.\",\n     \"type\": \"string\"\n    },\n    \"scrapeOnStart\": {\n     \"description\": \"Scrape metrics upon start, useful to avoid waiting for 'scrape_interval' for the first round of metrics.\",\n     \"type\": \"boolean\"\n    },\n    \"tag\": {\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"nodeExporterMetrics\": {\n   \"description\": \"NodeExporterMetrics defines Node Exporter Metrics Input configuration.\",\n   \"properties\": {\n    \"path\": {\n     \"properties\": {\n      \"procfs\": {\n       \"description\": \"The mount point used to collect process information and metrics.\",\n       \"type\": \"string\"\n      },\n      \"sysfs\": {\n       \"description\": \"The path in the filesystem used to collect system metrics.\",\n       \"type\": \"string\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"scrapeInterval\": {\n     \"description\": \"The rate at which metrics are collected from the host operating system, default is 5 seconds.\",\n     \"type\": \"string\"\n    },\n    \"tag\": {\n     \"description\": \"Tag name associated to all records comming from this plugin.\",\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"prometheusScrapeMetrics\": {\n   \"description\": \"PrometheusScrapeMetrics  defines Prometheus Scrape Metrics Input configuration.\",\n   \"properties\": {\n    \"host\": {\n     \"description\": \"The host of the prometheus metric endpoint that you want to scrape\",\n     \"type\": \"string\"\n    },\n    \"metricsPath\": {\n     \"description\": \"The metrics URI endpoint, that must start with a forward slash, deflaut: /metrics\",\n     \"type\": \"string\"\n    },\n    \"port\": {\n     \"description\": \"The port of the promethes metric endpoint that you want to scrape\",\n     \"format\": \"int32\",\n     \"maximum\": 65535,\n     \"minimum\": 1,\n     \"type\": \"integer\"\n    },\n    \"scrapeInterval\": {\n     \"description\": \"The interval to scrape metrics, default: 10s\",\n     \"type\": \"string\"\n    },\n    \"tag\": {\n     \"description\": \"Tag name associated to all records comming from this plugin\",\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"systemd\": {\n   \"description\": \"Systemd defines Systemd Input configuration.\",\n   \"properties\": {\n    \"db\": {\n     \"description\": \"Specify the database file to keep track of monitored files and offsets.\",\n     \"type\": \"string\"\n    },\n    \"dbSync\": {\n     \"description\": \"Set a default synchronization (I/O) method. values: Extra, Full, Normal, Off. This flag affects how the internal SQLite engine do synchronization to disk, for more details about each option please refer to this section. note: this option was introduced on Fluent Bit v1.4.6.\",\n     \"enum\": [\n      \"Extra\",\n      \"Full\",\n      \"Normal\",\n      \"Off\"\n     ],\n     \"type\": \"string\"\n    },\n    \"maxEntries\": {\n     \"description\": \"When Fluent Bit starts, the Journal might have a high number of logs in the queue. In order to avoid delays and reduce memory usage, this option allows to specify the maximum number of log entries that can be processed per round. Once the limit is reached, Fluent Bit will continue processing the remaining log entries once Journald performs the notification.\",\n     \"type\": \"integer\"\n    },\n    \"maxFields\": {\n     \"description\": \"Set a maximum number of fields (keys) allowed per record.\",\n     \"type\": \"integer\"\n    },\n    \"path\": {\n     \"description\": \"Optional path to the Systemd journal directory, if not set, the plugin will use default paths to read local-only logs.\",\n     \"type\": \"string\"\n    },\n    \"readFromTail\": {\n     \"description\": \"Start reading new entries. Skip entries already stored in Journald.\",\n     \"enum\": [\n      \"on\",\n      \"off\"\n     ],\n     \"type\": \"string\"\n    },\n    \"stripUnderscores\": {\n     \"description\": \"Remove the leading underscore of the Journald field (key). For example the Journald field _PID becomes the key PID.\",\n     \"enum\": [\n      \"on\",\n      \"off\"\n     ],\n     \"type\": \"string\"\n    },\n    \"systemdFilter\": {\n     \"description\": \"Allows to perform a query over logs that contains a specific Journald key/value pairs, e.g: _SYSTEMD_UNIT=UNIT. The Systemd_Filter option can be specified multiple times in the input section to apply multiple filters as required.\",\n     \"items\": {\n      \"type\": \"string\"\n     },\n     \"type\": \"array\"\n    },\n    \"systemdFilterType\": {\n     \"description\": \"Define the filter type when Systemd_Filter is specified multiple times. Allowed values are And and Or. With And a record is matched only when all of the Systemd_Filter have a match. With Or a record is matched when any of the Systemd_Filter has a match.\",\n     \"enum\": [\n      \"And\",\n      \"Or\"\n     ],\n     \"type\": \"string\"\n    },\n    \"tag\": {\n     \"description\": \"The tag is used to route messages but on Systemd plugin there is an extra functionality: if the tag includes a star/wildcard, it will be expanded with the Systemd Unit file (e.g: host.* =\\u003e host.UNIT_NAME).\",\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  },\n  \"tail\": {\n   \"description\": \"Tail defines Tail Input configuration.\",\n   \"properties\": {\n    \"bufferChunkSize\": {\n     \"description\": \"Set the initial buffer size to read files data. This value is used too to increase buffer size. The value must be according to the Unit Size specification.\",\n     \"pattern\": \"^\\\\d+(k|K|KB|kb|m|M|MB|mb|g|G|GB|gb)?$\",\n     \"type\": \"string\"\n    },\n    \"bufferMaxSize\": {\n     \"description\": \"Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines), this value is used to restrict how much the memory buffer can grow. If reading a file exceed this limit, the file is removed from the monitored file list The value must be according to the Unit Size specification.\",\n     \"pattern\": \"^\\\\d+(k|K|KB|kb|m|M|MB|mb|g|G|GB|gb)?$\",\n     \"type\": \"string\"\n    },\n    \"db\": {\n     \"description\": \"Specify the database file to keep track of monitored files and offsets.\",\n     \"type\": \"string\"\n    },\n    \"dbSync\": {\n     \"description\": \"Set a default synchronization (I/O) method. Values: Extra, Full, Normal, Off.\",\n     \"enum\": [\n      \"Extra\",\n      \"Full\",\n      \"Normal\",\n      \"Off\"\n     ],\n     \"type\": \"string\"\n    },\n    \"disableInotifyWatcher\": {\n     \"description\": \"DisableInotifyWatcher will disable inotify and use the file stat watcher instead.\",\n     \"type\": \"boolean\"\n    },\n    \"dockerMode\": {\n     \"description\": \"If enabled, the plugin will recombine split Docker log lines before passing them to any parser as configured above. This mode cannot be used at the same time as Multiline.\",\n     \"type\": \"boolean\"\n    },\n    \"dockerModeFlushSeconds\": {\n     \"description\": \"Wait period time in seconds to flush queued unfinished split lines.\",\n     \"format\": \"int64\",\n     \"type\": \"integer\"\n    },\n    \"excludePath\": {\n     \"description\": \"Set one or multiple shell patterns separated by commas to exclude files matching a certain criteria, e.g: exclude_path=*.gz,*.zip\",\n     \"type\": \"string\"\n    },\n    \"ignoredOlder\": {\n     \"description\": \"Ignores records which are older than this time in seconds. Supports m,h,d (minutes, hours, days) syntax. Default behavior is to read all records from specified files. Only available when a Parser is specificied and it can parse the time of a record.\",\n     \"pattern\": \"^\\\\d+(m|h|d)?$\",\n     \"type\": \"string\"\n    },\n    \"key\": {\n     \"description\": \"When a message is unstructured (no parser applied), it's appended as a string under the key name log. This option allows to define an alternative name for that key.\",\n     \"type\": \"string\"\n    },\n    \"memBufLimit\": {\n     \"description\": \"Set a limit of memory that Tail plugin can use when appending data to the Engine. If the limit is reach, it will be paused; when the data is flushed it resumes.\",\n     \"type\": \"string\"\n    },\n    \"multiline\": {\n     \"description\": \"If enabled, the plugin will try to discover multiline messages and use the proper parsers to compose the outgoing messages. Note that when this option is enabled the Parser option is not used.\",\n     \"type\": \"boolean\"\n    },\n    \"multilineFlushSeconds\": {\n     \"description\": \"Wait period time in seconds to process queued multiline messages\",\n     \"format\": \"int64\",\n     \"type\": \"integer\"\n    },\n    \"multilineParser\": {\n     \"description\": \"This will help to reassembly multiline messages originally split by Docker or CRI Specify one or Multiline Parser definition to apply to the content.\",\n     \"type\": \"string\"\n    },\n    \"parser\": {\n     \"description\": \"Specify the name of a parser to interpret the entry as a structured message.\",\n     \"type\": \"string\"\n    },\n    \"parserFirstline\": {\n     \"description\": \"Name of the parser that matchs the beginning of a multiline message. Note that the regular expression defined in the parser must include a group name (named capture)\",\n     \"type\": \"string\"\n    },\n    \"parserN\": {\n     \"description\": \"Optional-extra parser to interpret and structure multiline entries. This option can be used to define multiple parsers.\",\n     \"items\": {\n      \"type\": \"string\"\n     },\n     \"type\": \"array\"\n    },\n    \"path\": {\n     \"description\": \"Pattern specifying a specific log files or multiple ones through the use of common wildcards.\",\n     \"type\": \"string\"\n    },\n    \"pathKey\": {\n     \"description\": \"If enabled, it appends the name of the monitored file as part of the record. The value assigned becomes the key in the map.\",\n     \"type\": \"string\"\n    },\n    \"readFromHead\": {\n     \"description\": \"For new discovered files on start (without a database offset/position), read the content from the head of the file, not tail.\",\n     \"type\": \"boolean\"\n    },\n    \"refreshIntervalSeconds\": {\n     \"description\": \"The interval of refreshing the list of watched files in seconds.\",\n     \"format\": \"int64\",\n     \"type\": \"integer\"\n    },\n    \"rotateWaitSeconds\": {\n     \"description\": \"Specify the number of extra time in seconds to monitor a file once is rotated in case some pending data is flushed.\",\n     \"format\": \"int64\",\n     \"type\": \"integer\"\n    },\n    \"skipLongLines\": {\n     \"description\": \"When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file. Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.\",\n     \"type\": \"boolean\"\n    },\n    \"tag\": {\n     \"description\": \"Set a tag (with regex-extract fields) that will be placed on lines read. E.g. kube.\\u003cnamespace_name\\u003e.\\u003cpod_name\\u003e.\\u003ccontainer_name\\u003e\",\n     \"type\": \"string\"\n    },\n    \"tagRegex\": {\n     \"description\": \"Set a regex to exctract fields from the file\",\n     \"type\": \"string\"\n    }\n   },\n   \"type\": \"object\"\n  }\n },\n \"title\": \"Cluster Input\",\n \"type\": \"object\"\n}"}