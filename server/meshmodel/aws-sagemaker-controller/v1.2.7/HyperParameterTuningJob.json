{
  "id": "00000000-0000-0000-0000-000000000000",
  "kind": "HyperParameterTuningJob",
  "apiVersion": "sagemaker.services.k8s.aws/v1alpha1",
  "displayName": "Hyper Parameter Tuning Job",
  "format": "JSON",
  "hostID": "00000000-0000-0000-0000-000000000000",
  "metadata": {
   "capabilities": "",
   "defaultData": "",
   "genealogy": "",
   "isAnnotation": false,
   "isNamespaced": true,
   "primaryColor": "#01A88D",
   "secondaryColor": "",
   "shape": "rectangle",
   "shapePolygonPoints": "",
   "styleOverrides": "",
   "styles": "",
   "subCategory": "",
   "svgColor": "\u003csvg viewBox=\"0 0 40 40\" xmlns=\"http://www.w3.org/2000/svg\"\u003e        \u003cg id=\"Icon-Architecture/32/Arch_Amazon-SageMaker-Studio-Lab_32\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e        \u003cg id=\"Icon-Architecture-BG/32/Machine-Learning\" fill=\"#01A88D\"\u003e            \u003crect id=\"Rectangle\" x=\"0\" y=\"0\" width=\"40\" height=\"40\"\u003e\u003c/rect\u003e        \u003c/g\u003e        \u003cg id=\"Icon-Service/32/Amazon-SageMaker-Studio-Lab_32\" transform=\"translate(6.000000, 6.000000)\" fill=\"#FFFFFF\"\u003e            \u003cpath d=\"M18,21.0722264 L27,21.0722264 L27,7.07222639 L18,7.07222639 L18,21.0722264 Z M17,21.0722264 L17,7.07222639 L15,7.07222639 L15,9.07222639 L16,9.07222639 L16,10.0722264 L15,10.0722264 L15,13.0722264 L16,13.0722264 L16,14.0722264 L15,14.0722264 L15,17.0722264 L16,17.0722264 L16,18.0722264 L15,18.0722264 L15,21.0722264 L17,21.0722264 Z M28,6.57222639 L28,21.5722264 C28,21.8482264 27.776,22.0722264 27.5,22.0722264 L14.5,22.0722264 C14.224,22.0722264 14,21.8482264 14,21.5722264 L14,18.0722264 L13,18.0722264 L13,17.0722264 L14,17.0722264 L14,14.0722264 L13,14.0722264 L13,13.0722264 L14,13.0722264 L14,10.0722264 L13,10.0722264 L13,9.07222639 L14,9.07222639 L14,6.57222639 C14,6.29622639 14.224,6.07222639 14.5,6.07222639 L27.5,6.07222639 C27.776,6.07222639 28,6.29622639 28,6.57222639 L28,6.57222639 Z M14,23.0722264 L15,23.0722264 L15,25.5722264 C15,25.7612264 14.892,25.9342264 14.724,26.0192264 L10.724,28.0192264 C10.653,28.0542264 10.576,28.0722264 10.5,28.0722264 C10.414,28.0722264 10.329,28.0502264 10.252,28.0062264 L3.252,24.0062264 C3.096,23.9172264 3,23.7512264 3,23.5722264 L3,18.9002264 L0.273,17.5182264 C0.105,17.4332264 0,17.2602264 0,17.0722264 L0,10.5722264 C0,10.4052264 0.084,10.2492264 0.223,10.1562264 L3,8.30422639 L3,4.07222639 C3,3.89022639 3.1,3.72222639 3.259,3.63422639 L9.745,0.0612263904 C9.885,-0.0137736096 10.052,-0.0207736096 10.195,0.0452263904 L14.709,2.11722639 C14.886,2.19922639 15,2.37722639 15,2.57222639 L15,5.07222639 L14,5.07222639 L14,2.89322639 L10.007,1.05922639 L9,1.61322639 L9,6.07222639 L8,6.07222639 L8,2.16422639 L4,4.36722639 L4,7.79522639 L7.478,9.96922639 L10,8.27822639 L10,6.07222639 L11,6.07222639 L11,8.54522639 C11,8.71222639 10.917,8.86722639 10.778,8.96122639 L8,10.8222264 L8,13.0722264 L11,13.0722264 L11,14.0722264 L7.5,14.0722264 C7.224,14.0722264 7,13.8482264 7,13.5722264 L7,10.8492264 L3.879,8.89822639 C3.85,8.93222639 3.815,8.96322639 3.777,8.98822639 L1,10.8392264 L1,13.5782264 L4.199,11.1722264 L4.801,11.9712264 L1,14.8302264 L1,16.7652264 L3.726,18.1472264 C3.747,18.1572264 3.756,18.1792264 3.775,18.1922264 L6.18,16.1882264 L6.82,16.9562264 L4,19.3062264 L4,23.2822264 L6.655,24.7992264 L8,23.6992264 L8,18.0722264 L9,18.0722264 L9,22.8802264 L11.684,20.6852264 L12.316,21.4592264 L7.585,25.3302264 L10.516,27.0052264 L14,25.2632264 L14,23.0722264 Z\" id=\"Fill-3\"\u003e\u003c/path\u003e        \u003c/g\u003e    \u003c/g\u003e\u003c/svg\u003e",
   "svgComplete": "",
   "svgWhite": "\u003csvg viewBox=\"0 0 40 40\" xmlns=\"http://www.w3.org/2000/svg\"\u003e  \u003cg id=\"Icon-Architecture/32/Arch_Amazon-SageMaker-Studio-Lab_32\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e  \u003cg id=\"Icon-Service/32/Amazon-SageMaker-Studio-Lab_32\" transform=\"translate(6.000000, 6.000000)\" fill=\"#FFFFFF\"\u003e \u003cpath d=\"M18,21.0722264 L27,21.0722264 L27,7.07222639 L18,7.07222639 L18,21.0722264 Z M17,21.0722264 L17,7.07222639 L15,7.07222639 L15,9.07222639 L16,9.07222639 L16,10.0722264 L15,10.0722264 L15,13.0722264 L16,13.0722264 L16,14.0722264 L15,14.0722264 L15,17.0722264 L16,17.0722264 L16,18.0722264 L15,18.0722264 L15,21.0722264 L17,21.0722264 Z M28,6.57222639 L28,21.5722264 C28,21.8482264 27.776,22.0722264 27.5,22.0722264 L14.5,22.0722264 C14.224,22.0722264 14,21.8482264 14,21.5722264 L14,18.0722264 L13,18.0722264 L13,17.0722264 L14,17.0722264 L14,14.0722264 L13,14.0722264 L13,13.0722264 L14,13.0722264 L14,10.0722264 L13,10.0722264 L13,9.07222639 L14,9.07222639 L14,6.57222639 C14,6.29622639 14.224,6.07222639 14.5,6.07222639 L27.5,6.07222639 C27.776,6.07222639 28,6.29622639 28,6.57222639 L28,6.57222639 Z M14,23.0722264 L15,23.0722264 L15,25.5722264 C15,25.7612264 14.892,25.9342264 14.724,26.0192264 L10.724,28.0192264 C10.653,28.0542264 10.576,28.0722264 10.5,28.0722264 C10.414,28.0722264 10.329,28.0502264 10.252,28.0062264 L3.252,24.0062264 C3.096,23.9172264 3,23.7512264 3,23.5722264 L3,18.9002264 L0.273,17.5182264 C0.105,17.4332264 0,17.2602264 0,17.0722264 L0,10.5722264 C0,10.4052264 0.084,10.2492264 0.223,10.1562264 L3,8.30422639 L3,4.07222639 C3,3.89022639 3.1,3.72222639 3.259,3.63422639 L9.745,0.0612263904 C9.885,-0.0137736096 10.052,-0.0207736096 10.195,0.0452263904 L14.709,2.11722639 C14.886,2.19922639 15,2.37722639 15,2.57222639 L15,5.07222639 L14,5.07222639 L14,2.89322639 L10.007,1.05922639 L9,1.61322639 L9,6.07222639 L8,6.07222639 L8,2.16422639 L4,4.36722639 L4,7.79522639 L7.478,9.96922639 L10,8.27822639 L10,6.07222639 L11,6.07222639 L11,8.54522639 C11,8.71222639 10.917,8.86722639 10.778,8.96122639 L8,10.8222264 L8,13.0722264 L11,13.0722264 L11,14.0722264 L7.5,14.0722264 C7.224,14.0722264 7,13.8482264 7,13.5722264 L7,10.8492264 L3.879,8.89822639 C3.85,8.93222639 3.815,8.96322639 3.777,8.98822639 L1,10.8392264 L1,13.5782264 L4.199,11.1722264 L4.801,11.9712264 L1,14.8302264 L1,16.7652264 L3.726,18.1472264 C3.747,18.1572264 3.756,18.1792264 3.775,18.1922264 L6.18,16.1882264 L6.82,16.9562264 L4,19.3062264 L4,23.2822264 L6.655,24.7992264 L8,23.6992264 L8,18.0722264 L9,18.0722264 L9,22.8802264 L11.684,20.6852264 L12.316,21.4592264 L7.585,25.3302264 L10.516,27.0052264 L14,25.2632264 L14,23.0722264 Z\" id=\"Fill-3\"\u003e\u003c/path\u003e \u003c/g\u003e \u003c/g\u003e\u003c/svg\u003e"
  },
  "model": {
   "id": "00000000-0000-0000-0000-000000000000",
   "name": "aws-sagemaker-controller",
   "version": "v1.2.7",
   "displayName": "aws-sagemaker-controller",
   "hostID": "00000000-0000-0000-0000-000000000000",
   "category": {
    "name": "",
    "metadata": null
   },
   "metadata": {
    "source_uri": "git://github.com/aws-controllers-k8s/sagemaker-controller/main/helm"
   },
   "components": null,
   "relationships": null
  },
  "schema": "{\n \"description\": \"HyperParameterTuningJob is the Schema for the HyperParameterTuningJobs API\",\n \"properties\": {\n  \"spec\": {\n   \"description\": \"HyperParameterTuningJobSpec defines the desired state of HyperParameterTuningJob.\",\n   \"properties\": {\n    \"hyperParameterTuningJobConfig\": {\n     \"description\": \"The HyperParameterTuningJobConfig object that describes the tuning job, including\\nthe search strategy, the objective metric used to evaluate training jobs,\\nranges of parameters to search, and resource limits for the tuning job. For\\nmore information, see How Hyperparameter Tuning Works (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html).\",\n     \"properties\": {\n      \"hyperParameterTuningJobObjective\": {\n       \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n       \"properties\": {\n        \"metricName\": {\n         \"type\": \"string\"\n        },\n        \"type_\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"parameterRanges\": {\n       \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n       \"properties\": {\n        \"categoricalParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of categorical hyperparameters to tune.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"values\": {\n            \"items\": {\n             \"type\": \"string\"\n            },\n            \"type\": \"array\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"continuousParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of continuous hyperparameters to tune.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"integerParameterRanges\": {\n         \"items\": {\n          \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"resourceLimits\": {\n       \"description\": \"Specifies the maximum number of training jobs and parallel training jobs\\nthat a hyperparameter tuning job can launch.\",\n       \"properties\": {\n        \"maxNumberOfTrainingJobs\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"maxParallelTrainingJobs\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"strategy\": {\n       \"description\": \"The strategy hyperparameter tuning uses to find the best combination of hyperparameters\\nfor your model.\",\n       \"type\": \"string\"\n      },\n      \"trainingJobEarlyStoppingType\": {\n       \"type\": \"string\"\n      },\n      \"tuningJobCompletionCriteria\": {\n       \"description\": \"The job completion criteria.\",\n       \"properties\": {\n        \"targetObjectiveMetricValue\": {\n         \"type\": \"number\"\n        }\n       },\n       \"type\": \"object\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"hyperParameterTuningJobName\": {\n     \"description\": \"The name of the tuning job. This name is the prefix for the names of all\\ntraining jobs that this tuning job launches. The name must be unique within\\nthe same Amazon Web Services account and Amazon Web Services Region. The\\nname must have 1 to 32 characters. Valid characters are a-z, A-Z, 0-9, and\\n: + = @ _ % - (hyphen). The name is not case sensitive.\",\n     \"type\": \"string\"\n    },\n    \"tags\": {\n     \"description\": \"An array of key-value pairs. You can use tags to categorize your Amazon Web\\nServices resources in different ways, for example, by purpose, owner, or\\nenvironment. For more information, see Tagging Amazon Web Services Resources\\n(https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).\\n\\n\\nTags that you specify for the tuning job are also added to all training jobs\\nthat the tuning job launches.\",\n     \"items\": {\n      \"description\": \"A tag object that consists of a key and an optional value, used to manage\\nmetadata for SageMaker Amazon Web Services resources.\\n\\n\\nYou can add tags to notebook instances, training jobs, hyperparameter tuning\\njobs, batch transform jobs, models, labeling jobs, work teams, endpoint configurations,\\nand endpoints. For more information on adding tags to SageMaker resources,\\nsee AddTags.\\n\\n\\nFor more information on adding metadata to your Amazon Web Services resources\\nwith tagging, see Tagging Amazon Web Services resources (https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html).\\nFor advice on best practices for managing Amazon Web Services resources with\\ntagging, see Tagging Best Practices: Implement an Effective Amazon Web Services\\nResource Tagging Strategy (https://d1.awsstatic.com/whitepapers/aws-tagging-best-practices.pdf).\",\n      \"properties\": {\n       \"key\": {\n        \"type\": \"string\"\n       },\n       \"value\": {\n        \"type\": \"string\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"trainingJobDefinition\": {\n     \"description\": \"The HyperParameterTrainingJobDefinition object that describes the training\\njobs that this tuning job launches, including static hyperparameters, input\\ndata configuration, output data configuration, resource configuration, and\\nstopping condition.\",\n     \"properties\": {\n      \"algorithmSpecification\": {\n       \"description\": \"Specifies which training algorithm to use for training jobs that a hyperparameter\\ntuning job launches and the metrics to monitor.\",\n       \"properties\": {\n        \"algorithmName\": {\n         \"type\": \"string\"\n        },\n        \"metricDefinitions\": {\n         \"items\": {\n          \"description\": \"Specifies a metric that the training algorithm writes to stderr or stdout.\\nSageMakerhyperparameter tuning captures all defined metrics. You specify\\none metric that a hyperparameter tuning job uses as its objective metric\\nto choose the best training job.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"regex\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"trainingImage\": {\n         \"type\": \"string\"\n        },\n        \"trainingInputMode\": {\n         \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"checkpointConfig\": {\n       \"description\": \"Contains information about the output location for managed spot training\\ncheckpoint data.\",\n       \"properties\": {\n        \"localPath\": {\n         \"type\": \"string\"\n        },\n        \"s3URI\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"definitionName\": {\n       \"type\": \"string\"\n      },\n      \"enableInterContainerTrafficEncryption\": {\n       \"type\": \"boolean\"\n      },\n      \"enableManagedSpotTraining\": {\n       \"type\": \"boolean\"\n      },\n      \"enableNetworkIsolation\": {\n       \"type\": \"boolean\"\n      },\n      \"hyperParameterRanges\": {\n       \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n       \"properties\": {\n        \"categoricalParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of categorical hyperparameters to tune.\",\n          \"properties\": {\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"values\": {\n            \"items\": {\n             \"type\": \"string\"\n            },\n            \"type\": \"array\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"continuousParameterRanges\": {\n         \"items\": {\n          \"description\": \"A list of continuous hyperparameters to tune.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"integerParameterRanges\": {\n         \"items\": {\n          \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n          \"properties\": {\n           \"maxValue\": {\n            \"type\": \"string\"\n           },\n           \"minValue\": {\n            \"type\": \"string\"\n           },\n           \"name\": {\n            \"type\": \"string\"\n           },\n           \"scalingType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"inputDataConfig\": {\n       \"items\": {\n        \"description\": \"A channel is a named input source that training algorithms can consume.\",\n        \"properties\": {\n         \"channelName\": {\n          \"type\": \"string\"\n         },\n         \"compressionType\": {\n          \"type\": \"string\"\n         },\n         \"contentType\": {\n          \"type\": \"string\"\n         },\n         \"dataSource\": {\n          \"description\": \"Describes the location of the channel data.\",\n          \"properties\": {\n           \"fileSystemDataSource\": {\n            \"description\": \"Specifies a file system data source for a channel.\",\n            \"properties\": {\n             \"directoryPath\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemAccessMode\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemID\": {\n              \"type\": \"string\"\n             },\n             \"fileSystemType\": {\n              \"type\": \"string\"\n             }\n            },\n            \"type\": \"object\"\n           },\n           \"s3DataSource\": {\n            \"description\": \"Describes the S3 data source.\",\n            \"properties\": {\n             \"attributeNames\": {\n              \"items\": {\n               \"type\": \"string\"\n              },\n              \"type\": \"array\"\n             },\n             \"instanceGroupNames\": {\n              \"items\": {\n               \"type\": \"string\"\n              },\n              \"type\": \"array\"\n             },\n             \"s3DataDistributionType\": {\n              \"type\": \"string\"\n             },\n             \"s3DataType\": {\n              \"type\": \"string\"\n             },\n             \"s3URI\": {\n              \"type\": \"string\"\n             }\n            },\n            \"type\": \"object\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"inputMode\": {\n          \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n          \"type\": \"string\"\n         },\n         \"recordWrapperType\": {\n          \"type\": \"string\"\n         },\n         \"shuffleConfig\": {\n          \"description\": \"A configuration for a shuffle option for input data in a channel. If you\\nuse S3Prefix for S3DataType, the results of the S3 key prefix matches are\\nshuffled. If you use ManifestFile, the order of the S3 object references\\nin the ManifestFile is shuffled. If you use AugmentedManifestFile, the order\\nof the JSON lines in the AugmentedManifestFile is shuffled. The shuffling\\norder is determined using the Seed value.\\n\\n\\nFor Pipe input mode, when ShuffleConfig is specified shuffling is done at\\nthe start of every epoch. With large datasets, this ensures that the order\\nof the training data is different for each epoch, and it helps reduce bias\\nand possible overfitting. In a multi-node training job when ShuffleConfig\\nis combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled\\nacross nodes so that the content sent to a particular node on the first epoch\\nmight be sent to a different node on the second epoch.\",\n          \"properties\": {\n           \"seed\": {\n            \"format\": \"int64\",\n            \"type\": \"integer\"\n           }\n          },\n          \"type\": \"object\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"type\": \"array\"\n      },\n      \"outputDataConfig\": {\n       \"description\": \"Provides information about how to store model training results (model artifacts).\",\n       \"properties\": {\n        \"kmsKeyID\": {\n         \"type\": \"string\"\n        },\n        \"s3OutputPath\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"resourceConfig\": {\n       \"description\": \"Describes the resources, including machine learning (ML) compute instances\\nand ML storage volumes, to use for model training.\",\n       \"properties\": {\n        \"instanceCount\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"instanceGroups\": {\n         \"items\": {\n          \"description\": \"Defines an instance group for heterogeneous cluster training. When requesting\\na training job using the CreateTrainingJob (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)\\nAPI, you can configure multiple instance groups .\",\n          \"properties\": {\n           \"instanceCount\": {\n            \"format\": \"int64\",\n            \"type\": \"integer\"\n           },\n           \"instanceGroupName\": {\n            \"type\": \"string\"\n           },\n           \"instanceType\": {\n            \"type\": \"string\"\n           }\n          },\n          \"type\": \"object\"\n         },\n         \"type\": \"array\"\n        },\n        \"instanceType\": {\n         \"type\": \"string\"\n        },\n        \"keepAlivePeriodInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"volumeKMSKeyID\": {\n         \"type\": \"string\"\n        },\n        \"volumeSizeInGB\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"retryStrategy\": {\n       \"description\": \"The retry strategy to use when a training job fails due to an InternalServerError.\\nRetryStrategy is specified as part of the CreateTrainingJob and CreateHyperParameterTuningJob\\nrequests. You can add the StoppingCondition parameter to the request to limit\\nthe training time for the complete job.\",\n       \"properties\": {\n        \"maximumRetryAttempts\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"roleARN\": {\n       \"type\": \"string\"\n      },\n      \"staticHyperParameters\": {\n       \"additionalProperties\": {\n        \"type\": \"string\"\n       },\n       \"type\": \"object\"\n      },\n      \"stoppingCondition\": {\n       \"description\": \"Specifies a limit to how long a model training job or model compilation job\\ncan run. It also specifies how long a managed spot training job has to complete.\\nWhen the job reaches the time limit, SageMaker ends the training or compilation\\njob. Use this API to cap model training costs.\\n\\n\\nTo stop a training job, SageMaker sends the algorithm the SIGTERM signal,\\nwhich delays job termination for 120 seconds. Algorithms can use this 120-second\\nwindow to save the model artifacts, so the results of training are not lost.\\n\\n\\nThe training algorithms provided by SageMaker automatically save the intermediate\\nresults of a model training job when possible. This attempt to save artifacts\\nis only a best effort case as model might not be in a state from which it\\ncan be saved. For example, if training has just started, the model might\\nnot be ready to save. When saved, this intermediate data is a valid model\\nartifact. You can use it to create a model with CreateModel.\\n\\n\\nThe Neural Topic Model (NTM) currently does not support saving intermediate\\nmodel artifacts. When training NTMs, make sure that the maximum runtime is\\nsufficient for the training job to complete.\",\n       \"properties\": {\n        \"maxRuntimeInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        },\n        \"maxWaitTimeInSeconds\": {\n         \"format\": \"int64\",\n         \"type\": \"integer\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"tuningObjective\": {\n       \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n       \"properties\": {\n        \"metricName\": {\n         \"type\": \"string\"\n        },\n        \"type_\": {\n         \"type\": \"string\"\n        }\n       },\n       \"type\": \"object\"\n      },\n      \"vpcConfig\": {\n       \"description\": \"Specifies a VPC that your training jobs and hosted models have access to.\\nControl access to and from your training and model containers by configuring\\nthe VPC. For more information, see Protect Endpoints by Using an Amazon Virtual\\nPrivate Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)\\nand Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).\",\n       \"properties\": {\n        \"securityGroupIDs\": {\n         \"items\": {\n          \"type\": \"string\"\n         },\n         \"type\": \"array\"\n        },\n        \"subnets\": {\n         \"items\": {\n          \"type\": \"string\"\n         },\n         \"type\": \"array\"\n        }\n       },\n       \"type\": \"object\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"trainingJobDefinitions\": {\n     \"description\": \"A list of the HyperParameterTrainingJobDefinition objects launched for this\\ntuning job.\",\n     \"items\": {\n      \"description\": \"Defines the training jobs launched by a hyperparameter tuning job.\",\n      \"properties\": {\n       \"algorithmSpecification\": {\n        \"description\": \"Specifies which training algorithm to use for training jobs that a hyperparameter\\ntuning job launches and the metrics to monitor.\",\n        \"properties\": {\n         \"algorithmName\": {\n          \"type\": \"string\"\n         },\n         \"metricDefinitions\": {\n          \"items\": {\n           \"description\": \"Specifies a metric that the training algorithm writes to stderr or stdout.\\nSageMakerhyperparameter tuning captures all defined metrics. You specify\\none metric that a hyperparameter tuning job uses as its objective metric\\nto choose the best training job.\",\n           \"properties\": {\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"regex\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"trainingImage\": {\n          \"type\": \"string\"\n         },\n         \"trainingInputMode\": {\n          \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"checkpointConfig\": {\n        \"description\": \"Contains information about the output location for managed spot training\\ncheckpoint data.\",\n        \"properties\": {\n         \"localPath\": {\n          \"type\": \"string\"\n         },\n         \"s3URI\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"definitionName\": {\n        \"type\": \"string\"\n       },\n       \"enableInterContainerTrafficEncryption\": {\n        \"type\": \"boolean\"\n       },\n       \"enableManagedSpotTraining\": {\n        \"type\": \"boolean\"\n       },\n       \"enableNetworkIsolation\": {\n        \"type\": \"boolean\"\n       },\n       \"hyperParameterRanges\": {\n        \"description\": \"Specifies ranges of integer, continuous, and categorical hyperparameters\\nthat a hyperparameter tuning job searches. The hyperparameter tuning job\\nlaunches training jobs with hyperparameter values within these ranges to\\nfind the combination of values that result in the training job with the best\\nperformance as measured by the objective metric of the hyperparameter tuning\\njob.\\n\\n\\nThe maximum number of items specified for Array Members refers to the maximum\\nnumber of hyperparameters for each range and also the maximum for the hyperparameter\\ntuning job itself. That is, the sum of the number of hyperparameters for\\nall the ranges can't exceed the maximum number specified.\",\n        \"properties\": {\n         \"categoricalParameterRanges\": {\n          \"items\": {\n           \"description\": \"A list of categorical hyperparameters to tune.\",\n           \"properties\": {\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"values\": {\n             \"items\": {\n              \"type\": \"string\"\n             },\n             \"type\": \"array\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"continuousParameterRanges\": {\n          \"items\": {\n           \"description\": \"A list of continuous hyperparameters to tune.\",\n           \"properties\": {\n            \"maxValue\": {\n             \"type\": \"string\"\n            },\n            \"minValue\": {\n             \"type\": \"string\"\n            },\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"scalingType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"integerParameterRanges\": {\n          \"items\": {\n           \"description\": \"For a hyperparameter of the integer type, specifies the range that a hyperparameter\\ntuning job searches.\",\n           \"properties\": {\n            \"maxValue\": {\n             \"type\": \"string\"\n            },\n            \"minValue\": {\n             \"type\": \"string\"\n            },\n            \"name\": {\n             \"type\": \"string\"\n            },\n            \"scalingType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"inputDataConfig\": {\n        \"items\": {\n         \"description\": \"A channel is a named input source that training algorithms can consume.\",\n         \"properties\": {\n          \"channelName\": {\n           \"type\": \"string\"\n          },\n          \"compressionType\": {\n           \"type\": \"string\"\n          },\n          \"contentType\": {\n           \"type\": \"string\"\n          },\n          \"dataSource\": {\n           \"description\": \"Describes the location of the channel data.\",\n           \"properties\": {\n            \"fileSystemDataSource\": {\n             \"description\": \"Specifies a file system data source for a channel.\",\n             \"properties\": {\n              \"directoryPath\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemAccessMode\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemID\": {\n               \"type\": \"string\"\n              },\n              \"fileSystemType\": {\n               \"type\": \"string\"\n              }\n             },\n             \"type\": \"object\"\n            },\n            \"s3DataSource\": {\n             \"description\": \"Describes the S3 data source.\",\n             \"properties\": {\n              \"attributeNames\": {\n               \"items\": {\n                \"type\": \"string\"\n               },\n               \"type\": \"array\"\n              },\n              \"instanceGroupNames\": {\n               \"items\": {\n                \"type\": \"string\"\n               },\n               \"type\": \"array\"\n              },\n              \"s3DataDistributionType\": {\n               \"type\": \"string\"\n              },\n              \"s3DataType\": {\n               \"type\": \"string\"\n              },\n              \"s3URI\": {\n               \"type\": \"string\"\n              }\n             },\n             \"type\": \"object\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"inputMode\": {\n           \"description\": \"The training input mode that the algorithm supports. For more information\\nabout input modes, see Algorithms (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).\\n\\n\\nPipe mode\\n\\n\\nIf an algorithm supports Pipe mode, Amazon SageMaker streams data directly\\nfrom Amazon S3 to the container.\\n\\n\\nFile mode\\n\\n\\nIf an algorithm supports File mode, SageMaker downloads the training data\\nfrom S3 to the provisioned ML storage volume, and mounts the directory to\\nthe Docker volume for the training container.\\n\\n\\nYou must provision the ML storage volume with sufficient capacity to accommodate\\nthe data downloaded from S3. In addition to the training data, the ML storage\\nvolume also stores the output model. The algorithm container uses the ML\\nstorage volume to also store intermediate information, if any.\\n\\n\\nFor distributed algorithms, training data is distributed uniformly. Your\\ntraining duration is predictable if the input data objects sizes are approximately\\nthe same. SageMaker does not split the files any further for model training.\\nIf the object sizes are skewed, training won't be optimal as the data distribution\\nis also skewed when one host in a training cluster is overloaded, thus becoming\\na bottleneck in training.\\n\\n\\nFastFile mode\\n\\n\\nIf an algorithm supports FastFile mode, SageMaker streams data directly from\\nS3 to the container with no code changes, and provides file system access\\nto the data. Users can author their training script to interact with these\\nfiles as if they were stored on disk.\\n\\n\\nFastFile mode works best when the data is read sequentially. Augmented manifest\\nfiles aren't supported. The startup time is lower when there are fewer files\\nin the S3 bucket provided.\",\n           \"type\": \"string\"\n          },\n          \"recordWrapperType\": {\n           \"type\": \"string\"\n          },\n          \"shuffleConfig\": {\n           \"description\": \"A configuration for a shuffle option for input data in a channel. If you\\nuse S3Prefix for S3DataType, the results of the S3 key prefix matches are\\nshuffled. If you use ManifestFile, the order of the S3 object references\\nin the ManifestFile is shuffled. If you use AugmentedManifestFile, the order\\nof the JSON lines in the AugmentedManifestFile is shuffled. The shuffling\\norder is determined using the Seed value.\\n\\n\\nFor Pipe input mode, when ShuffleConfig is specified shuffling is done at\\nthe start of every epoch. With large datasets, this ensures that the order\\nof the training data is different for each epoch, and it helps reduce bias\\nand possible overfitting. In a multi-node training job when ShuffleConfig\\nis combined with S3DataDistributionType of ShardedByS3Key, the data is shuffled\\nacross nodes so that the content sent to a particular node on the first epoch\\nmight be sent to a different node on the second epoch.\",\n           \"properties\": {\n            \"seed\": {\n             \"format\": \"int64\",\n             \"type\": \"integer\"\n            }\n           },\n           \"type\": \"object\"\n          }\n         },\n         \"type\": \"object\"\n        },\n        \"type\": \"array\"\n       },\n       \"outputDataConfig\": {\n        \"description\": \"Provides information about how to store model training results (model artifacts).\",\n        \"properties\": {\n         \"kmsKeyID\": {\n          \"type\": \"string\"\n         },\n         \"s3OutputPath\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"resourceConfig\": {\n        \"description\": \"Describes the resources, including machine learning (ML) compute instances\\nand ML storage volumes, to use for model training.\",\n        \"properties\": {\n         \"instanceCount\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"instanceGroups\": {\n          \"items\": {\n           \"description\": \"Defines an instance group for heterogeneous cluster training. When requesting\\na training job using the CreateTrainingJob (https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)\\nAPI, you can configure multiple instance groups .\",\n           \"properties\": {\n            \"instanceCount\": {\n             \"format\": \"int64\",\n             \"type\": \"integer\"\n            },\n            \"instanceGroupName\": {\n             \"type\": \"string\"\n            },\n            \"instanceType\": {\n             \"type\": \"string\"\n            }\n           },\n           \"type\": \"object\"\n          },\n          \"type\": \"array\"\n         },\n         \"instanceType\": {\n          \"type\": \"string\"\n         },\n         \"keepAlivePeriodInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"volumeKMSKeyID\": {\n          \"type\": \"string\"\n         },\n         \"volumeSizeInGB\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"retryStrategy\": {\n        \"description\": \"The retry strategy to use when a training job fails due to an InternalServerError.\\nRetryStrategy is specified as part of the CreateTrainingJob and CreateHyperParameterTuningJob\\nrequests. You can add the StoppingCondition parameter to the request to limit\\nthe training time for the complete job.\",\n        \"properties\": {\n         \"maximumRetryAttempts\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"roleARN\": {\n        \"type\": \"string\"\n       },\n       \"staticHyperParameters\": {\n        \"additionalProperties\": {\n         \"type\": \"string\"\n        },\n        \"type\": \"object\"\n       },\n       \"stoppingCondition\": {\n        \"description\": \"Specifies a limit to how long a model training job or model compilation job\\ncan run. It also specifies how long a managed spot training job has to complete.\\nWhen the job reaches the time limit, SageMaker ends the training or compilation\\njob. Use this API to cap model training costs.\\n\\n\\nTo stop a training job, SageMaker sends the algorithm the SIGTERM signal,\\nwhich delays job termination for 120 seconds. Algorithms can use this 120-second\\nwindow to save the model artifacts, so the results of training are not lost.\\n\\n\\nThe training algorithms provided by SageMaker automatically save the intermediate\\nresults of a model training job when possible. This attempt to save artifacts\\nis only a best effort case as model might not be in a state from which it\\ncan be saved. For example, if training has just started, the model might\\nnot be ready to save. When saved, this intermediate data is a valid model\\nartifact. You can use it to create a model with CreateModel.\\n\\n\\nThe Neural Topic Model (NTM) currently does not support saving intermediate\\nmodel artifacts. When training NTMs, make sure that the maximum runtime is\\nsufficient for the training job to complete.\",\n        \"properties\": {\n         \"maxRuntimeInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         },\n         \"maxWaitTimeInSeconds\": {\n          \"format\": \"int64\",\n          \"type\": \"integer\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"tuningObjective\": {\n        \"description\": \"Defines the objective metric for a hyperparameter tuning job. Hyperparameter\\ntuning uses the value of this metric to evaluate the training jobs it launches,\\nand returns the training job that results in either the highest or lowest\\nvalue for this metric, depending on the value you specify for the Type parameter.\",\n        \"properties\": {\n         \"metricName\": {\n          \"type\": \"string\"\n         },\n         \"type_\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"vpcConfig\": {\n        \"description\": \"Specifies a VPC that your training jobs and hosted models have access to.\\nControl access to and from your training and model containers by configuring\\nthe VPC. For more information, see Protect Endpoints by Using an Amazon Virtual\\nPrivate Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)\\nand Protect Training Jobs by Using an Amazon Virtual Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).\",\n        \"properties\": {\n         \"securityGroupIDs\": {\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         },\n         \"subnets\": {\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"type\": \"object\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"warmStartConfig\": {\n     \"description\": \"Specifies the configuration for starting the hyperparameter tuning job using\\none or more previous tuning jobs as a starting point. The results of previous\\ntuning jobs are used to inform which combinations of hyperparameters to search\\nover in the new tuning job.\\n\\n\\nAll training jobs launched by the new hyperparameter tuning job are evaluated\\nby using the objective metric. If you specify IDENTICAL_DATA_AND_ALGORITHM\\nas the WarmStartType value for the warm start configuration, the training\\njob that performs the best in the new tuning job is compared to the best\\ntraining jobs from the parent tuning jobs. From these, the training job that\\nperforms the best as measured by the objective metric is returned as the\\noverall best training job.\\n\\n\\nAll training jobs launched by parent hyperparameter tuning jobs and the new\\nhyperparameter tuning jobs count against the limit of training jobs for the\\ntuning job.\",\n     \"properties\": {\n      \"parentHyperParameterTuningJobs\": {\n       \"items\": {\n        \"description\": \"A previously completed or stopped hyperparameter tuning job to be used as\\na starting point for a new hyperparameter tuning job.\",\n        \"properties\": {\n         \"hyperParameterTuningJobName\": {\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"type\": \"array\"\n      },\n      \"warmStartType\": {\n       \"type\": \"string\"\n      }\n     },\n     \"type\": \"object\"\n    }\n   },\n   \"required\": [\n    \"hyperParameterTuningJobConfig\",\n    \"hyperParameterTuningJobName\"\n   ],\n   \"type\": \"object\"\n  }\n },\n \"title\": \"Hyper Parameter Tuning Job\",\n \"type\": \"object\"\n}"
 }