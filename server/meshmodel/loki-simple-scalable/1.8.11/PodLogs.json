{"kind":"PodLogs","apiVersion":"monitoring.grafana.com/v1alpha1","displayName":"Pod Logs","format":"JSON","hostname":"","hostID":"00000000-0000-0000-0000-000000000000","displayhostname":"","metadata":{"capabilities":"","genealogy":"","isAnnotation":false,"isModelAnnotation":"FALSE","isNamespaced":true,"logoURL":"","model":"loki-simple-scalable","modelDisplayName":"Loki Simple Scalable","primaryColor":"#00B39F","published":false,"secondaryColor":"#00D3A9","shape":"circle","styleOverrides":"","subCategory":"Logging","svgColor":"","svgComplete":"","svgWhite":""},"model":{"name":"loki-simple-scalable","version":"1.8.11","displayName":"Loki Simple Scalable","hostname":"","hostID":"00000000-0000-0000-0000-000000000000","displayhostname":"","category":{"name":"Observability and Analysis","metadata":null},"metadata":{"source_uri":"https://github.com/grafana/helm-charts/releases/download/loki-simple-scalable-1.8.11/loki-simple-scalable-1.8.11.tgz"},"components":null,"relationships":null},"schema":"{\n \"description\": \"PodLogs defines how to collect logs for a pod.\",\n \"properties\": {\n  \"spec\": {\n   \"description\": \"Spec holds the specification of the desired behavior for the PodLogs.\",\n   \"properties\": {\n    \"jobLabel\": {\n     \"description\": \"The label to use to retrieve the job name from.\",\n     \"type\": \"string\"\n    },\n    \"namespaceSelector\": {\n     \"description\": \"Selector to select which namespaces the Pod objects are discovered from.\",\n     \"properties\": {\n      \"any\": {\n       \"description\": \"Boolean describing whether all namespaces are selected in contrast to a list restricting them.\",\n       \"type\": \"boolean\"\n      },\n      \"matchNames\": {\n       \"description\": \"List of namespace names to select from.\",\n       \"items\": {\n        \"type\": \"string\"\n       },\n       \"type\": \"array\"\n      }\n     },\n     \"type\": \"object\"\n    },\n    \"pipelineStages\": {\n     \"description\": \"Pipeline stages for this pod. Pipeline stages allow for transforming and filtering log lines.\",\n     \"items\": {\n      \"description\": \"PipelineStageSpec defines an individual pipeline stage. Each stage type is mutually exclusive and no more than one may be set per stage. \\n More information on pipelines can be found in the Promtail documentation: https://grafana.com/docs/loki/latest/clients/promtail/pipelines/\",\n      \"properties\": {\n       \"cri\": {\n        \"description\": \"CRI is a parsing stage that reads log lines using the standard CRI logging format. Supply cri: {} to enable.\",\n        \"type\": \"object\"\n       },\n       \"docker\": {\n        \"description\": \"Docker is a parsing stage that reads log lines using the standard Docker logging format. Supply docker: {} to enable.\",\n        \"type\": \"object\"\n       },\n       \"drop\": {\n        \"description\": \"Drop is a filtering stage that lets you drop certain logs.\",\n        \"properties\": {\n         \"dropCounterReason\": {\n          \"description\": \"Every time a log line is dropped the metric logentry_dropped_lines_total will be incremented. A \\\"reason\\\" label is added, and can be customized by providing a custom value here. Defaults to \\\"drop_stage.\\\"\",\n          \"type\": \"string\"\n         },\n         \"expression\": {\n          \"description\": \"RE2 regular exprssion. \\n If source is provided, the regex will attempt to match the source. \\n If no source is provided, then the regex will attempt to attach the log line. \\n If the provided regex matches the log line or a provided source, the line will be dropped.\",\n          \"type\": \"string\"\n         },\n         \"longerThan\": {\n          \"description\": \"LongerThan will drop a log line if it its content is longer than this value (in bytes). Can be expressed as an integer (8192) or a number with a suffix (8kb).\",\n          \"type\": \"string\"\n         },\n         \"olderThan\": {\n          \"description\": \"OlderThan will be parsed as a Go duration. If the log line's timestamp is older than the current time minus the provided duration it will be dropped.\",\n          \"type\": \"string\"\n         },\n         \"source\": {\n          \"description\": \"Name from the extract data to parse. If empty, uses the log message.\",\n          \"type\": \"string\"\n         },\n         \"value\": {\n          \"description\": \"Value can only be specified when source is specified. If the value provided is an exact match for the given source then the line will be dropped. \\n Mutually exclusive with expression.\",\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"json\": {\n        \"description\": \"JSON is a parsing stage that reads the log line as JSON and accepts JMESPath expressions to extract data. \\n Information on JMESPath: http://jmespath.org/\",\n        \"properties\": {\n         \"expressions\": {\n          \"additionalProperties\": {\n           \"type\": \"string\"\n          },\n          \"description\": \"Set of the key/value pairs of JMESPath expressions. The key will be the key in the extracted data while the expression will be the value, evaluated as a JMESPath from the source data. \\n Literal JMESPath exprssions can be done by wrapping a key in double quotes, which then must be wrapped again in single quotes in YAML so they get passed to the JMESPath parser.\",\n          \"type\": \"object\"\n         },\n         \"source\": {\n          \"description\": \"Name from the extracted data to parse as JSON. If empty, uses entire log message.\",\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"labelAllow\": {\n        \"description\": \"LabelAllow is an action stage that only allows the provided labels to be included in the label set that is sent to Loki with the log entry.\",\n        \"items\": {\n         \"type\": \"string\"\n        },\n        \"type\": \"array\"\n       },\n       \"labelDrop\": {\n        \"description\": \"LabelDrop is an action stage that drops labels from the label set that is sent to Loki with the log entry.\",\n        \"items\": {\n         \"type\": \"string\"\n        },\n        \"type\": \"array\"\n       },\n       \"labels\": {\n        \"additionalProperties\": {\n         \"type\": \"string\"\n        },\n        \"description\": \"Labels is an action stage that takes data from the extracted map and modifies the label set that is sent to Loki with the log entry. \\n The key is REQUIRED and represents the name for the label that will be created. Value is optional and will be the name from extracted data to use for the value of the label. If the value is not provided, it defaults to match the key.\",\n        \"type\": \"object\"\n       },\n       \"match\": {\n        \"description\": \"Match is a filtering stage that conditionally applies a set of stages or drop entries when a log entry matches a configurable LogQL stream selector and filter expressions.\",\n        \"properties\": {\n         \"action\": {\n          \"description\": \"Determines what action is taken when the selector matches the log line. Can be keep or drop. Defaults to keep. When set to drop, entries will be dropped and no later metrics will be recorded. Stages must be empty when dropping metrics.\",\n          \"type\": \"string\"\n         },\n         \"dropCounterReason\": {\n          \"description\": \"Every time a log line is dropped the metric logentry_dropped_lines_total will be incremented. A \\\"reason\\\" label is added, and can be customized by providing a custom value here. Defaults to \\\"match_stage.\\\"\",\n          \"type\": \"string\"\n         },\n         \"pipelineName\": {\n          \"description\": \"Names the pipeline. When defined, creates an additional label in the pipeline_duration_seconds histogram, where the value is concatenated with job_name using an underscore.\",\n          \"type\": \"string\"\n         },\n         \"selector\": {\n          \"description\": \"LogQL stream selector and filter expressions. Required.\",\n          \"type\": \"string\"\n         },\n         \"stages\": {\n          \"description\": \"Nested set of pipeline stages to execute when action: keep and the log line matches selector. \\n An example value for stages may be: \\n stages: | - json: {} - labelAllow: [foo, bar] \\n Note that stages is a string because SIG API Machinery does not support recursive types, and so it cannot be validated for correctness. Be careful not to mistype anything.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"selector\"\n        ],\n        \"type\": \"object\"\n       },\n       \"metrics\": {\n        \"additionalProperties\": {\n         \"description\": \"MetricsStageSpec is an action stage that allows for defining and updating metrics based on data from the extracted map. Created metrics are not pushed to Loki or Prometheus and are instead exposed via the /metrics endpoint of the Grafana Agent pod. The Grafana Agent Operator should be configured with a MetricsInstance that discovers the logging DaemonSet to collect metrics created by this stage.\",\n         \"properties\": {\n          \"action\": {\n           \"description\": \"The action to take against the metric. Required. \\n Must be either \\\"inc\\\" or \\\"add\\\" for type: counter or type: histogram. When type: gauge, must be one of \\\"set\\\", \\\"inc\\\", \\\"dec\\\", \\\"add\\\", or \\\"sub\\\". \\n \\\"add\\\", \\\"set\\\", or \\\"sub\\\" requires the extracted value to be convertible to a positive float.\",\n           \"type\": \"string\"\n          },\n          \"buckets\": {\n           \"description\": \"Buckets to create. Bucket values must be convertible to float64s. Extremely large or small numbers are subject to some loss of precision. Only valid for type: histogram.\",\n           \"items\": {\n            \"type\": \"string\"\n           },\n           \"type\": \"array\"\n          },\n          \"countEntryBytes\": {\n           \"description\": \"If true all log line bytes will be counted. Can only be set with matchAll: true and action: add. \\n Only valid for type: counter.\",\n           \"type\": \"boolean\"\n          },\n          \"description\": {\n           \"description\": \"Sets the description for the created metric.\",\n           \"type\": \"string\"\n          },\n          \"matchAll\": {\n           \"description\": \"If true all log lines will be counted without attempting to match the source to the extracted map. Mutually exclusive with value. \\n Only valid for type: counter.\",\n           \"type\": \"boolean\"\n          },\n          \"maxIdleDuration\": {\n           \"description\": \"Label values on metrics are dynamic which can cause exported metrics to go stale. To prevent unbounded cardinality, any metrics not updated within MaxIdleDuration will be removed. \\n Must be greater or equal to 1s. Defaults to 5m.\",\n           \"type\": \"string\"\n          },\n          \"prefix\": {\n           \"description\": \"Sets the custom prefix name for the metric. Defaults to \\\"promtail_custom_\\\".\",\n           \"type\": \"string\"\n          },\n          \"source\": {\n           \"description\": \"Key from the extracted data map to use for the metric. Defaults to the metrics name if not present.\",\n           \"type\": \"string\"\n          },\n          \"type\": {\n           \"description\": \"The metric type to create. Must be one of counter, gauge, histogram. Required.\",\n           \"type\": \"string\"\n          },\n          \"value\": {\n           \"description\": \"Filters down source data and only changes the metric if the targeted value exactly matches the provided string. If not present, all data will match.\",\n           \"type\": \"string\"\n          }\n         },\n         \"required\": [\n          \"action\",\n          \"type\"\n         ],\n         \"type\": \"object\"\n        },\n        \"description\": \"Metrics is an action stage that allows for defining and updating metrics based on data from the extracted map. Created metrics are not pushed to Loki or Prometheus and are instead exposed via the /metrics endpoint of the Grafana Agent pod. The Grafana Agent Operator should be configured with a MetricsInstance that discovers the logging DaemonSet to collect metrics created by this stage.\",\n        \"type\": \"object\"\n       },\n       \"multiline\": {\n        \"description\": \"Multiline stage merges multiple lines into a multiline block before passing it on to the next stage in the pipeline.\",\n        \"properties\": {\n         \"firstLine\": {\n          \"description\": \"RE2 regular expression. Creates a new multiline block when matched. Required.\",\n          \"type\": \"string\"\n         },\n         \"maxLines\": {\n          \"description\": \"Maximum number of lines a block can have. A new block is started if the number of lines surpasses this value. Defaults to 128.\",\n          \"type\": \"integer\"\n         },\n         \"maxWaitTime\": {\n          \"description\": \"Maximum time to wait before passing on the multiline block to the next stage if no new lines are received. Defaults to 3s.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"firstLine\"\n        ],\n        \"type\": \"object\"\n       },\n       \"output\": {\n        \"description\": \"Output stage is an action stage that takes data from the extracted map and changes the log line that will be sent to Loki.\",\n        \"properties\": {\n         \"source\": {\n          \"description\": \"Name from extract data to use for the log entry. Required.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"source\"\n        ],\n        \"type\": \"object\"\n       },\n       \"pack\": {\n        \"description\": \"Pack is a transform stage that lets you embed extracted values and labels into the log line by packing the log line and labels inside of a JSON object.\",\n        \"properties\": {\n         \"ingestTimestamp\": {\n          \"description\": \"If the resulting log line should use any existing timestamp or use time.Now() when the line was created. Set to true when combining several log streams from different containers to avoid out of order errors.\",\n          \"type\": \"boolean\"\n         },\n         \"labels\": {\n          \"description\": \"Name from extracted data or line labels. Requiried. Labels provided here are automatically removed from output labels.\",\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"required\": [\n         \"labels\"\n        ],\n        \"type\": \"object\"\n       },\n       \"regex\": {\n        \"description\": \"Regex is a parsing stage that parses a log line using a regular expression.  Named capture groups in the regex allows for adding data into the extracted map.\",\n        \"properties\": {\n         \"expression\": {\n          \"description\": \"RE2 regular expression. Each capture group MUST be named. Required.\",\n          \"type\": \"string\"\n         },\n         \"source\": {\n          \"description\": \"Name from extracted data to parse. If empty, defaults to using the log message.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"expression\"\n        ],\n        \"type\": \"object\"\n       },\n       \"replace\": {\n        \"description\": \"Replace is a parsing stage that parses a log line using a regular expression and replaces the log line. Named capture groups in the regex allows for adding data into the extracted map.\",\n        \"properties\": {\n         \"expression\": {\n          \"description\": \"RE2 regular expression. Each capture group MUST be named. Required.\",\n          \"type\": \"string\"\n         },\n         \"replace\": {\n          \"description\": \"Value to replace the captured group with.\",\n          \"type\": \"string\"\n         },\n         \"source\": {\n          \"description\": \"Name from extracted data to parse. If empty, defaults to using the log message.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"expression\"\n        ],\n        \"type\": \"object\"\n       },\n       \"template\": {\n        \"description\": \"Template is a transform stage that manipulates the values in the extracted map using Go's template syntax.\",\n        \"properties\": {\n         \"source\": {\n          \"description\": \"Name from extracted data to parse. Required. If empty, defaults to using the log message.\",\n          \"type\": \"string\"\n         },\n         \"template\": {\n          \"description\": \"Go template string to use. Required. In additional to normal template functions, ToLower, ToUpper, Replace, Trim, TrimLeft, TrimRight, TrimPrefix, and TrimSpace are also available.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"source\",\n         \"template\"\n        ],\n        \"type\": \"object\"\n       },\n       \"tenant\": {\n        \"description\": \"Tenant is an action stage that sets the tenant ID for the log entry picking it from a field in the extracted data map. If the field is missing, the default LogsClientSpec.tenantId will be used.\",\n        \"properties\": {\n         \"source\": {\n          \"description\": \"Name from extracted data to use as the tenant ID. Mutually exclusive with value.\",\n          \"type\": \"string\"\n         },\n         \"value\": {\n          \"description\": \"Value to use for the template ID. Useful when this stage is used within a conditional pipeline such as match. Mutually exclusive with source.\",\n          \"type\": \"string\"\n         }\n        },\n        \"type\": \"object\"\n       },\n       \"timestamp\": {\n        \"description\": \"Timestamp is an action stage that can change the timestamp of a log line before it is sent to Loki. If not present, the timestamp of a log line defaults to the time when the log line was read.\",\n        \"properties\": {\n         \"actionOnFailure\": {\n          \"description\": \"Action to take when the timestamp can't be extracted or parsed. Can be skip or fudge. Defaults to fudge.\",\n          \"type\": \"string\"\n         },\n         \"fallbackFormats\": {\n          \"description\": \"Fallback formats to try if format fails.\",\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         },\n         \"format\": {\n          \"description\": \"Determines format of the time string. Required. Can be one of: ANSIC, UnixDate, RubyDate, RFC822, RFC822Z, RFC850, RFC1123, RFC1123Z, RFC3339, RFC3339Nano, Unix, UnixMs, UnixUs, UnixNs.\",\n          \"type\": \"string\"\n         },\n         \"location\": {\n          \"description\": \"IANA Timezone Database string.\",\n          \"type\": \"string\"\n         },\n         \"source\": {\n          \"description\": \"Name from extracted data to use as the timestamp. Required.\",\n          \"type\": \"string\"\n         }\n        },\n        \"required\": [\n         \"format\",\n         \"source\"\n        ],\n        \"type\": \"object\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"podTargetLabels\": {\n     \"description\": \"PodTargetLabels transfers labels on the Kubernetes Pod onto the target.\",\n     \"items\": {\n      \"type\": \"string\"\n     },\n     \"type\": \"array\"\n    },\n    \"relabelings\": {\n     \"description\": \"RelabelConfigs to apply to logs before delivering. Grafana Agent Operator automatically adds relabelings for a few standard Kubernetes fields and replaces original scrape job name with __tmp_logs_job_name. \\n More info: https://grafana.com/docs/loki/latest/clients/promtail/configuration/#relabel_configs\",\n     \"items\": {\n      \"description\": \"RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `\\u003cmetric_relabel_configs\\u003e`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs\",\n      \"properties\": {\n       \"action\": {\n        \"default\": \"replace\",\n        \"description\": \"Action to perform based on regex matching. Default is 'replace'\",\n        \"enum\": [\n         \"replace\",\n         \"keep\",\n         \"drop\",\n         \"hashmod\",\n         \"labelmap\",\n         \"labeldrop\",\n         \"labelkeep\"\n        ],\n        \"type\": \"string\"\n       },\n       \"modulus\": {\n        \"description\": \"Modulus to take of the hash of the source label values.\",\n        \"format\": \"int64\",\n        \"type\": \"integer\"\n       },\n       \"regex\": {\n        \"description\": \"Regular expression against which the extracted value is matched. Default is '(.*)'\",\n        \"type\": \"string\"\n       },\n       \"replacement\": {\n        \"description\": \"Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'\",\n        \"type\": \"string\"\n       },\n       \"separator\": {\n        \"description\": \"Separator placed between concatenated source label values. default is ';'.\",\n        \"type\": \"string\"\n       },\n       \"sourceLabels\": {\n        \"description\": \"The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.\",\n        \"items\": {\n         \"description\": \"LabelName is a valid Prometheus label name which may only contain ASCII letters, numbers, as well as underscores.\",\n         \"pattern\": \"^[a-zA-Z_][a-zA-Z0-9_]*$\",\n         \"type\": \"string\"\n        },\n        \"type\": \"array\"\n       },\n       \"targetLabel\": {\n        \"description\": \"Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.\",\n        \"type\": \"string\"\n       }\n      },\n      \"type\": \"object\"\n     },\n     \"type\": \"array\"\n    },\n    \"selector\": {\n     \"description\": \"Selector to select Pod objects. Required.\",\n     \"properties\": {\n      \"matchExpressions\": {\n       \"description\": \"matchExpressions is a list of label selector requirements. The requirements are ANDed.\",\n       \"items\": {\n        \"description\": \"A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.\",\n        \"properties\": {\n         \"key\": {\n          \"description\": \"key is the label key that the selector applies to.\",\n          \"type\": \"string\"\n         },\n         \"operator\": {\n          \"description\": \"operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.\",\n          \"type\": \"string\"\n         },\n         \"values\": {\n          \"description\": \"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.\",\n          \"items\": {\n           \"type\": \"string\"\n          },\n          \"type\": \"array\"\n         }\n        },\n        \"required\": [\n         \"key\",\n         \"operator\"\n        ],\n        \"type\": \"object\"\n       },\n       \"type\": \"array\"\n      },\n      \"matchLabels\": {\n       \"additionalProperties\": {\n        \"type\": \"string\"\n       },\n       \"description\": \"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is \\\"key\\\", the operator is \\\"In\\\", and the values array contains only \\\"value\\\". The requirements are ANDed.\",\n       \"type\": \"object\"\n      }\n     },\n     \"type\": \"object\"\n    }\n   },\n   \"required\": [\n    \"selector\"\n   ],\n   \"type\": \"object\"\n  }\n },\n \"title\": \"Pod Logs\",\n \"type\": \"object\"\n}"}